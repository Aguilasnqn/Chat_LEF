{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN5DC/TnjeVs0nHw7PA/Vue",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aguilasnqn/Chat_LEF/blob/main/linea_de_tiempo_de_videos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install youtube-transcript-api\n",
        "#!pip install pytube -q\n",
        "#from pytube import YouTube"
      ],
      "metadata": {
        "id": "Xpx1M_guHVNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "urlx=\"https://www.youtube.com/watch?v=zPw_xqn_Ztk\"\n",
        "#urlx=\"om/watch?vzPw_xqn_Ztk\"\n",
        "patron = r\"(?<=v=)([\\w-]+)\"\n",
        "urls = re.search(patron, urlx)\n",
        "if urls:\n",
        "  #resultado = '-'.join([url for url in urls])\n",
        "  resultado=urls[0]\n",
        "  print(resultado)\n",
        "\n",
        "#a= (urls[1])\n",
        "#print(a)\n",
        "#len(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T11U0ysy30j7",
        "outputId": "b2bab38f-f528-4c81-bdd8-0054ab6295e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "zPw_xqn_Ztk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install youtube-transcript-api\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "import json\n",
        "filename=\"/content/prueba6\"\n",
        "\n",
        "id = \"MANTtPfb1G0\"\n",
        "# parametros que recibe ls, video_ids, languages=('en',), continue_after_error=False, proxies=None,\n",
        "#                        cookies=None, preserve_formatting=False):\n",
        "transcript = YouTubeTranscriptApi.get_transcript(id,languages=('es',))\n",
        "# si quiero puedo grabar un a archivo.json\n",
        "with open(f'{filename}.json', 'w', encoding='utf-8') as json_file:\n",
        "            json.dump(transcript, json_file)"
      ],
      "metadata": {
        "id": "X3-Z9Q1zTeLB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ed342e2-c723-43f6-db8d-94c6fc3e513d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting youtube-transcript-api\n",
            "  Downloading youtube_transcript_api-0.6.2-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube-transcript-api) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2024.2.2)\n",
            "Installing collected packages: youtube-transcript-api\n",
            "Successfully installed youtube-transcript-api-0.6.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(transcript)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuOjbIVhBsRX",
        "outputId": "d52761c1-5dc3-4ba3-9cf4-096787bf7e8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'text': '[Música]', 'start': 0.0, 'duration': 3.04}, {'text': 'Esta es la segunda parte de la clase', 'start': 1.199, 'duration': 6.011}, {'text': 'número 25 te invito a empezar con', 'start': 3.04, 'duration': 25.92}, {'text': '[Música]', 'start': 7.21, 'duration': 23.0}, {'text': 'ella', 'start': 28.96, 'duration': 9.269}, {'text': '[Música]', 'start': 30.21, 'duration': 8.019}, {'text': 'el siguiente tema que tenemos que ver es', 'start': 38.399, 'duration': 4.721}, {'text': 'la tokenización y vamos rápidamente a', 'start': 40.399, 'duration': 4.281}, {'text': 'tratar de entender Qué es la', 'start': 43.12, 'duration': 4.279}, {'text': 'tokenización la tokenización es dividir', 'start': 44.68, 'duration': 5.8}, {'text': 'un texto en tokens los tokens son las', 'start': 47.399, 'duration': 5.96}, {'text': 'unidades individuales de un texto por lo', 'start': 50.48, 'duration': 5.8}, {'text': 'general eh van a ser palabras pero en', 'start': 53.359, 'duration': 4.641}, {'text': 'realidad la tokenización puede dividir', 'start': 56.28, 'duration': 4.04}, {'text': 'el texto en otras unidades que no sean', 'start': 58.0, 'duration': 5.28}, {'text': 'palabras aquí tengo un ejemplo basado en', 'start': 60.32, 'duration': 6.24}, {'text': 'python donde tengo un texto Hola mundo', 'start': 63.28, 'duration': 5.479}, {'text': 'coma Buenos días dentro de una variable', 'start': 66.56, 'duration': 4.32}, {'text': 'que se llama texto y luego lo que hago', 'start': 68.759, 'duration': 4.641}, {'text': 'justamente es aplicar el método split', 'start': 70.88, 'duration': 4.279}, {'text': 'que ustedes ya lo conocen por python que', 'start': 73.4, 'duration': 4.16}, {'text': 'lo que hace es dividir justamente un', 'start': 75.159, 'duration': 6.161}, {'text': 'texto en palabras y lo coloca dentro de', 'start': 77.56, 'duration': 5.199}, {'text': 'una variable que le he dado llamar', 'start': 81.32, 'duration': 3.96}, {'text': 'tokens y luego hago un PR de tokens con', 'start': 82.759, 'duration': 4.4}, {'text': 'lo cual lo que veo es que me sale la', 'start': 85.28, 'duration': 4.24}, {'text': 'palabra que tiene perdón la frase que', 'start': 87.159, 'duration': 4.64}, {'text': 'tiene tiene cuatro palabras con cada una', 'start': 89.52, 'duration': 4.279}, {'text': 'de sus palabras en una Ray', 'start': 91.799, 'duration': 3.561}, {'text': 'individualmente', 'start': 93.799, 'duration': 4.121}, {'text': 'identificadas fíjense que hay algo muy', 'start': 95.36, 'duration': 4.719}, {'text': 'importante aquí que en el caso de olola', 'start': 97.92, 'duration': 4.96}, {'text': 'y en el caso de mundo hay una diferencia', 'start': 100.079, 'duration': 5.08}, {'text': 'mundo tiene una coma y eso lo toma como', 'start': 102.88, 'duration': 4.76}, {'text': 'parte de la palabra y Díaz que es la', 'start': 105.159, 'duration': 4.481}, {'text': 'frase final tiene dos signos de', 'start': 107.64, 'duration': 3.64}, {'text': 'exclamación que también los toma como', 'start': 109.64, 'duration': 3.0}, {'text': 'parte de la palabra Bueno eso es parte', 'start': 111.28, 'duration': 2.479}, {'text': 'de lo que vamos a tener que empezar a', 'start': 112.64, 'duration': 4.68}, {'text': 'ver más adelante de si estas estas estos', 'start': 113.759, 'duration': 6.121}, {'text': 'separadores o estas expresiones que no', 'start': 117.32, 'duration': 4.96}, {'text': 'conforman una palabra del abecedario las', 'start': 119.88, 'duration': 4.76}, {'text': 'voy a querer juntar con la palabra las', 'start': 122.28, 'duration': 4.96}, {'text': 'voy a poder tratarlas como un token', 'start': 124.64, 'duration': 4.28}, {'text': 'aparte o simplemente voy a querer', 'start': 127.24, 'duration': 3.519}, {'text': 'prescindir de ellas que ya vamos a ver', 'start': 128.92, 'duration': 3.44}, {'text': 'más adelante que en realidad la', 'start': 130.759, 'duration': 3.081}, {'text': 'interpretación que se hace a través del', 'start': 132.36, 'duration': 4.4}, {'text': 'nlp muchas veces puede prescindir de', 'start': 133.84, 'duration': 6.22}, {'text': 'estos signos sin perder calidad de', 'start': 136.76, 'duration': 6.28}, {'text': '[Música]', 'start': 140.06, 'duration': 5.539}, {'text': 'interpretación como dijimos recién en la', 'start': 143.04, 'duration': 4.32}, {'text': 'evolución de la toca haciendo un', 'start': 145.599, 'duration': 3.681}, {'text': 'análisis mucho más fino del proceso', 'start': 147.36, 'duration': 3.959}, {'text': 'tenemos formas diferentes de tokenizar', 'start': 149.28, 'duration': 3.8}, {'text': 'en principio basado en palabras lo más', 'start': 151.319, 'duration': 4.401}, {'text': 'tradicional lo más común auto moto bueno', 'start': 153.08, 'duration': 4.48}, {'text': 'el elemento que sea representativo de', 'start': 155.72, 'duration': 4.2}, {'text': 'una palabra de un texto basada en', 'start': 157.56, 'duration': 5.84}, {'text': 'caracteres puedo tomar letras o números', 'start': 159.92, 'duration': 5.52}, {'text': 'o expresiones como la roba o lo que', 'start': 163.4, 'duration': 3.839}, {'text': 'debos recién una coma o un signo de', 'start': 165.44, 'duration': 4.36}, {'text': 'admiración o basado en su palabras Es', 'start': 167.239, 'duration': 5.201}, {'text': 'decir por aquí tengo una palabra que', 'start': 169.8, 'duration': 4.799}, {'text': 'está conformada por otras dos o que se', 'start': 172.44, 'duration': 3.6}, {'text': 'puede subdividir por el sentido que', 'start': 174.599, 'duration': 4.241}, {'text': 'tienen otras dos contraataque en contra', 'start': 176.04, 'duration': 4.32}, {'text': 'o ataque', 'start': 178.84, 'duration': 3.52}, {'text': 'bien consideraciones a tener presente un', 'start': 180.36, 'duration': 4.12}, {'text': 'poco lo que repasamos recién diferentes', 'start': 182.36, 'duration': 4.2}, {'text': 'casos de letra es decir tenemos letras', 'start': 184.48, 'duration': 3.6}, {'text': 'que tienen caracteres complicados como', 'start': 186.56, 'duration': 3.319}, {'text': 'puede ser un tilde una diéresis depende', 'start': 188.08, 'duration': 4.159}, {'text': 'del lenguaje que se trate y justamente', 'start': 189.879, 'duration': 3.761}, {'text': 'lo que tengo que tomar como criterio es', 'start': 192.239, 'duration': 4.761}, {'text': 'si voy a utilizar eso o no en el proceso', 'start': 193.64, 'duration': 5.76}, {'text': 'de aproximación que haga hacia', 'start': 197.0, 'duration': 4.36}, {'text': 'interpretar el texto que viene a mí que', 'start': 199.4, 'duration': 3.68}, {'text': 'yo transformo en un en un vector o en', 'start': 201.36, 'duration': 3.439}, {'text': 'una estructura de números por eso', 'start': 203.08, 'duration': 3.799}, {'text': 'también es importante tener en cuenta lo', 'start': 204.799, 'duration': 4.121}, {'text': 'que dijimos recién la forma de tocan ia', 'start': 206.879, 'duration': 4.121}, {'text': 'para ver si tomo los elementos o no de', 'start': 208.92, 'duration': 4.599}, {'text': 'manera individual o como parte colectiva', 'start': 211.0, 'duration': 5.239}, {'text': 'o parte de la expresión en cada palabra', 'start': 213.519, 'duration': 5.601}, {'text': 'donde está eh vinculado ese ese carácter', 'start': 216.239, 'duration': 6.121}, {'text': 'especial y justamente la puntuación ver', 'start': 219.12, 'duration': 5.399}, {'text': 'si la voy a tener en consideración o no', 'start': 222.36, 'duration': 4.64}, {'text': 'de acuerdo al sentido que yo busque de', 'start': 224.519, 'duration': 4.321}, {'text': 'el tipo de inteligencia que aplique para', 'start': 227.0, 'duration': 3.92}, {'text': 'la interpretación que haga en algunos', 'start': 228.84, 'duration': 4.2}, {'text': 'casos ustedes ya van a ver más adelante', 'start': 230.92, 'duration': 4.84}, {'text': 'que se puede prescindir de una coma se', 'start': 233.04, 'duration': 5.6}, {'text': 'puede prescindir de un punto o no y en', 'start': 235.76, 'duration': 4.839}, {'text': 'algunos casos el tomar la opción de', 'start': 238.64, 'duration': 5.12}, {'text': 'hacerlo no nos va a hacer peligrar la la', 'start': 240.599, 'duration': 5.28}, {'text': 'eficiencia como decía hace un rato de la', 'start': 243.76, 'duration': 4.88}, {'text': 'interpretación del', 'start': 245.879, 'duration': 2.761}, {'text': 'texto Obviamente que todo esto que', 'start': 248.92, 'duration': 4.319}, {'text': 'estamos hablando no hace otra cosa que', 'start': 251.079, 'duration': 4.72}, {'text': 'como dijimos hace un rato generar', 'start': 253.239, 'duration': 4.641}, {'text': 'información transformada de texto en', 'start': 255.799, 'duration': 4.081}, {'text': 'vectores pero para que la inteligencia', 'start': 257.88, 'duration': 4.079}, {'text': 'empiece a entender el sentido de ese', 'start': 259.88, 'duration': 4.24}, {'text': 'texto y empiece a serer distintos tipos', 'start': 261.959, 'duration': 4.361}, {'text': 'de tarea justamente con textos que', 'start': 264.12, 'duration': 4.639}, {'text': 'empiecen a aparecer como input Por ende', 'start': 266.32, 'duration': 5.52}, {'text': 'este tipo de información representa un', 'start': 268.759, 'duration': 4.88}, {'text': 'conjunto de datos que está a', 'start': 271.84, 'duration': 3.919}, {'text': 'disponibilidad de esa inteligencia para', 'start': 273.639, 'duration': 4.441}, {'text': 'ser entrenado Por ende ese volumen de', 'start': 275.759, 'duration': 4.401}, {'text': 'datos para el aprendizaje obviamente es', 'start': 278.08, 'duration': 4.6}, {'text': 'un factor muy importante y como cuando', 'start': 280.16, 'duration': 4.4}, {'text': 'vimos el resto de las inteligencias que', 'start': 282.68, 'duration': 4.2}, {'text': 'vimos en el curso o antes en el curso de', 'start': 284.56, 'duration': 4.56}, {'text': 'que venimos llevando adelante justamente', 'start': 286.88, 'duration': 4.36}, {'text': 'Cuanto más datos tengamos obviamente más', 'start': 289.12, 'duration': 4.04}, {'text': 'preciso y efectivo va a ser el modelo sí', 'start': 291.24, 'duration': 3.56}, {'text': 'sabemos que siempre hay un límite no', 'start': 293.16, 'duration': 2.84}, {'text': 'quiere decir que siempre tenga que ser', 'start': 294.8, 'duration': 3.52}, {'text': 'el número máximo Pero obviamente Cuanto', 'start': 296.0, 'duration': 4.16}, {'text': 'más tengamos en principio de Debería ser', 'start': 298.32, 'duration': 4.08}, {'text': 'ese algoritmo mucho más eficiente Por', 'start': 300.16, 'duration': 5.44}, {'text': 'ende o por ello Mejor dicho el el éxito', 'start': 302.4, 'duration': 5.12}, {'text': 'de los grandes este las grandes', 'start': 305.6, 'duration': 4.08}, {'text': 'aplicaciones que hay hoy como GP t4 que', 'start': 307.52, 'duration': 4.679}, {'text': 'han sido entrenadas con cantidades', 'start': 309.68, 'duration': 5.0}, {'text': 'enormes de información y de texto y por', 'start': 312.199, 'duration': 5.881}, {'text': 'eso el alto nivel de eferencia que', 'start': 314.68, 'duration': 6.12}, {'text': 'tienen un tema final a tener presente en', 'start': 318.08, 'duration': 4.88}, {'text': 'este proceso asociado a la tokenización', 'start': 320.8, 'duration': 4.239}, {'text': 'es el manejo de las letras minúsculas y', 'start': 322.96, 'duration': 5.0}, {'text': 'mayúsculas en realidad para la máquina', 'start': 325.039, 'duration': 6.28}, {'text': 'un hola donde la H está en mayúscula o', 'start': 327.96, 'duration': 4.959}, {'text': 'la misma palabra donde la H está en', 'start': 331.319, 'duration': 3.761}, {'text': 'minúscula son dos palabras totalmente', 'start': 332.919, 'duration': 3.601}, {'text': 'diferentes yo tenemos que tenerlo en', 'start': 335.08, 'duration': 3.72}, {'text': 'cuenta porque justamente si nosotros', 'start': 336.52, 'duration': 5.2}, {'text': 'ponemos esta o dejamos libre esta', 'start': 338.8, 'duration': 5.519}, {'text': 'diferenciación entre una palabra y otra', 'start': 341.72, 'duration': 4.4}, {'text': 'simplemente por tener la primera letra', 'start': 344.319, 'duration': 4.841}, {'text': 'mayúscula estamos creando un vector con', 'start': 346.12, 'duration': 5.72}, {'text': 'mayor dimensión ustedes imagínense que', 'start': 349.16, 'duration': 5.12}, {'text': 'todas las palabras tengan esta esta', 'start': 351.84, 'duration': 4.96}, {'text': 'situación de dos palabras diferentes por', 'start': 354.28, 'duration': 5.199}, {'text': 'tener la primera letra en mayúscula o no', 'start': 356.8, 'duration': 5.44}, {'text': 'estaría duplicando Prácticamente todo el', 'start': 359.479, 'duration': 4.121}, {'text': 'vocabulario literalmente todo el', 'start': 362.24, 'duration': 2.959}, {'text': 'vocabulario Por lo cual por ejemplo', 'start': 363.6, 'duration': 2.999}, {'text': 'recién el vector que teníamos 18', 'start': 365.199, 'duration': 2.801}, {'text': 'posiciones va a pasar a ser un vector de', 'start': 366.599, 'duration': 3.921}, {'text': '36 posiciones siendo que la palabra es', 'start': 368.0, 'duration': 4.319}, {'text': 'exactamente la misma con lo cual lo que', 'start': 370.52, 'duration': 3.399}, {'text': 'me conviene hacer como proceso de', 'start': 372.319, 'duration': 3.16}, {'text': 'tokenización o parte del proceso de', 'start': 373.919, 'duration': 4.641}, {'text': 'tokenización además de dividirlas con el', 'start': 375.479, 'duration': 4.961}, {'text': 'método split que vimos hace un rato es', 'start': 378.56, 'duration': 3.88}, {'text': 'aplicar lower para poner toda la', 'start': 380.44, 'duration': 4.8}, {'text': 'expresión en minúscula de esa manera mi', 'start': 382.44, 'duration': 5.039}, {'text': 'diccionario va a estar conformado por', 'start': 385.24, 'duration': 4.92}, {'text': 'cuatro palabras de otro modo modo yo', 'start': 387.479, 'duration': 4.361}, {'text': 'tendría que tener un diccionario donde', 'start': 390.16, 'duration': 5.0}, {'text': 'por ejemplo Hola mundo y buenos que', 'start': 391.84, 'duration': 5.759}, {'text': 'tiene la posibilidad de tener una', 'start': 395.16, 'duration': 3.8}, {'text': 'expresión en minúscula y mayúscula', 'start': 397.599, 'duration': 2.561}, {'text': 'tendría que tener contemplados los dos', 'start': 398.96, 'duration': 2.6}, {'text': 'casos con lo cual tenía un diccionario', 'start': 400.16, 'duration': 4.319}, {'text': 'de siete palabras en lugar de cuatro', 'start': 401.56, 'duration': 5.32}, {'text': 'como hay', 'start': 404.479, 'duration': 2.401}, {'text': 'aquí el siguiente concepto importante', 'start': 407.28, 'duration': 5.0}, {'text': 'son las stop words sí o palabras de', 'start': 409.84, 'duration': 4.84}, {'text': 'parada bien tenemos por ejemplo aquí una', 'start': 412.28, 'duration': 4.039}, {'text': 'frase de ejemplo que la he puesto en una', 'start': 414.68, 'duration': 4.359}, {'text': 'var de texto en algunos países los días', 'start': 416.319, 'duration': 5.681}, {'text': 'son muy largos y las noches muy cortas', 'start': 419.039, 'duration': 6.56}, {'text': 'bien si yo toqu eniso esta frase que', 'start': 422.0, 'duration': 8.12}, {'text': 'tiene 13 palabras tendría una toca de 12', 'start': 425.599, 'duration': 6.6}, {'text': 'palabras por qué Porque está la palabra', 'start': 430.12, 'duration': 3.919}, {'text': 'muy que se repite dos veces como vimos', 'start': 432.199, 'duration': 4.12}, {'text': 'recién el diccionario sería de 12', 'start': 434.039, 'duration': 4.321}, {'text': 'palabras a partir de este texto está', 'start': 436.319, 'duration': 5.641}, {'text': 'bien Ahora en esta frase existen lo que', 'start': 438.36, 'duration': 6.44}, {'text': 'se llaman stop Wars sí las spw Por lo', 'start': 441.96, 'duration': 5.76}, {'text': 'general son palabras que forman parte de', 'start': 444.8, 'duration': 6.119}, {'text': 'las frases pero representan algo que no', 'start': 447.72, 'duration': 5.68}, {'text': 'cambia el sentido de la frase y Por ende', 'start': 450.919, 'duration': 4.68}, {'text': 'se puede llegar a prescindir de ellas en', 'start': 453.4, 'duration': 5.479}, {'text': 'este caso por ejemplo las palabras en', 'start': 455.599, 'duration': 8.0}, {'text': 'los las muy e son palabras del lenguaje', 'start': 458.879, 'duration': 6.6}, {'text': 'español que están en todas partes Es', 'start': 463.599, 'duration': 3.401}, {'text': 'decir no va a ser algo que voy a', 'start': 465.479, 'duration': 2.921}, {'text': 'encontrar en esta frase y no voy a', 'start': 467.0, 'duration': 3.159}, {'text': 'encontrar en muchas otras frases porque', 'start': 468.4, 'duration': 3.799}, {'text': 'son justamente elementos clásicos de', 'start': 470.159, 'duration': 4.561}, {'text': 'nuestro lenguaje y Por ende justamente', 'start': 472.199, 'duration': 4.921}, {'text': 'no aportan mucho a la frase ni tampoco', 'start': 474.72, 'duration': 4.72}, {'text': 'cambian mucho el sentido de la frase si', 'start': 477.12, 'duration': 5.079}, {'text': 'esas stop Wars no están en este caso si', 'start': 479.44, 'duration': 5.039}, {'text': 'yo me', 'start': 482.199, 'duration': 2.28}, {'text': 'circunscribieron las work que', 'start': 492.479, 'duration': 5.68}, {'text': 'mencionábamos recién Entonces esto puede', 'start': 495.28, 'duration': 5.28}, {'text': 'verse que a la hora de leerlo desde la', 'start': 498.159, 'duration': 4.361}, {'text': 'que es nuestro conocimiento del lenguaje', 'start': 500.56, 'duration': 4.72}, {'text': 'podía representar una frase que se puede', 'start': 502.52, 'duration': 4.32}, {'text': 'interpretar más o menos Hacia dónde va', 'start': 505.28, 'duration': 4.0}, {'text': 'pero no es muy clara bueno Esto es muy', 'start': 506.84, 'duration': 4.56}, {'text': 'importante en el mundo en LP porque la', 'start': 509.28, 'duration': 4.239}, {'text': 'máquina sí lo va a poder interpretar de', 'start': 511.4, 'duration': 4.4}, {'text': 'manera correcta y lo que estoy haciendo', 'start': 513.519, 'duration': 5.281}, {'text': 'aquí es prescindiendo de una cantidad de', 'start': 515.8, 'duration': 5.84}, {'text': 'dimensiones en este supuesto vector si', 'start': 518.8, 'duration': 5.28}, {'text': 'contemplara las stop Word dentro que', 'start': 521.64, 'duration': 4.92}, {'text': 'justamente al no tenerlos se reduce el', 'start': 524.08, 'duration': 5.28}, {'text': 'vector yo gano como ustedes ya imaginan', 'start': 526.56, 'duration': 5.48}, {'text': 'por supuesto en velocidad en rapidez y', 'start': 529.36, 'duration': 5.52}, {'text': 'en eficiencia justamente teniendo menos', 'start': 532.04, 'duration': 4.52}, {'text': 'dimensiones que teniendo una cantidad de', 'start': 534.88, 'duration': 4.04}, {'text': 'dimensiones mayor y quizás innecesaria a', 'start': 536.56, 'duration': 5.0}, {'text': 'los fines del', 'start': 538.92, 'duration': 2.64}, {'text': 'nlp Bueno pero se terminaron las', 'start': 542.88, 'duration': 4.639}, {'text': 'palabras se terminaron las definiciones', 'start': 545.8, 'duration': 4.2}, {'text': 'y los conceptos es hora de aplicar', 'start': 547.519, 'duration': 5.041}, {'text': 'nuestro primer código de nlp para', 'start': 550.0, 'duration': 4.519}, {'text': 'empezar a trabajar en este caso', 'start': 552.56, 'duration': 4.76}, {'text': 'particular con stop Wars y tokenización', 'start': 554.519, 'duration': 6.161}, {'text': 'para ello tenemos este la pnl 1 que es', 'start': 557.32, 'duration': 5.0}, {'text': 'un archivo de colap que es el primero', 'start': 560.68, 'duration': 3.279}, {'text': 'con el cual vamos a empezar a trabajar y', 'start': 562.32, 'duration': 3.16}, {'text': 'es uno de los archivos que ustedes', 'start': 563.959, 'duration': 4.161}, {'text': 'tienen en el campo virtual vamos hacia', 'start': 565.48, 'duration': 4.919}, {'text': 'ello', 'start': 568.12, 'duration': 3.8}, {'text': 'aquí estamos entonces en el ámbito de', 'start': 570.399, 'duration': 4.401}, {'text': 'Cola con el la pnl 1 bien tenemos la', 'start': 571.92, 'duration': 5.12}, {'text': 'variable texto a la cual le ponemos la', 'start': 574.8, 'duration': 4.24}, {'text': 'misma frase que hablamos hace un rato en', 'start': 577.04, 'duration': 4.08}, {'text': 'algunos países los días son muy largos y', 'start': 579.04, 'duration': 4.08}, {'text': 'las noches muy cortas lo que vamos a', 'start': 581.12, 'duration': 4.44}, {'text': 'hacer como primera medida es importar la', 'start': 583.12, 'duration': 6.92}, {'text': 'librería nltk nltk significa librería', 'start': 585.56, 'duration': 8.2}, {'text': 'natural Language tool kit Entonces', 'start': 590.04, 'duration': 5.32}, {'text': 'tenemos que importar esa librería y', 'start': 593.76, 'duration': 3.12}, {'text': 'tenemos que bajar dos archivos que son', 'start': 595.36, 'duration': 2.8}, {'text': 'importantes el primero para la', 'start': 596.88, 'duration': 3.56}, {'text': 'tokenización y el segundo para trabajar', 'start': 598.16, 'duration': 4.48}, {'text': 'con las stop World Así que vamos', 'start': 600.44, 'duration': 3.6}, {'text': 'entonces con la primer celda que no lo', 'start': 602.64, 'duration': 3.04}, {'text': 'habíamos ejecutado que es poner dentro', 'start': 604.04, 'duration': 5.2}, {'text': 'de texto esa frase y luego importar', 'start': 605.68, 'duration': 5.8}, {'text': 'estas librerías paso seguido que lo', 'start': 609.24, 'duration': 3.64}, {'text': 'ponemos en una celda aparte pero lo', 'start': 611.48, 'duration': 3.68}, {'text': 'podríamos Haber puesto junto con las dos', 'start': 612.88, 'duration': 4.199}, {'text': 'las tres líneas anteriores Perdón', 'start': 615.16, 'duration': 5.56}, {'text': 'tenemos que también incorporar eh d nltk', 'start': 617.079, 'duration': 6.921}, {'text': 'Corpus stop Wars y d nltk tokenize Word', 'start': 620.72, 'duration': 6.2}, {'text': 'tokenize bien importamos esas librerías', 'start': 624.0, 'duration': 5.32}, {'text': 'también y ahora empezamos a ver el tema', 'start': 626.92, 'duration': 4.8}, {'text': 'de las stop Wars en principio voy a', 'start': 629.32, 'duration': 3.759}, {'text': 'crear una variable que le voy a poner', 'start': 631.72, 'duration': 4.559}, {'text': 'stop bajo Wars en la cual voy a volcar', 'start': 633.079, 'duration': 6.241}, {'text': 'todo el dicionario de palabras de stop', 'start': 636.279, 'duration': 5.641}, {'text': 'Wars que existen en el ámbito del', 'start': 639.32, 'duration': 5.079}, {'text': 'Castellano sí palabras que tienen que', 'start': 641.92, 'duration': 4.24}, {'text': 'ver justamente con lo que voy marcando', 'start': 644.399, 'duration': 3.601}, {'text': 'aquí arriba con esta librería stop Wars', 'start': 646.16, 'duration': 4.04}, {'text': 'que pertenece al natural Language', 'start': 648.0, 'duration': 5.32}, {'text': 'toolkit y de hago una impresión para que', 'start': 650.2, 'duration': 6.079}, {'text': 'se vea justamente Cuáles son todas las', 'start': 653.32, 'duration': 6.199}, {'text': 'stop Wars en español así que ejecuto', 'start': 656.279, 'duration': 5.921}, {'text': 'esta instrucción y aquí tengo una lista', 'start': 659.519, 'duration': 6.161}, {'text': 'muy larga que bueno la podrían tirar a', 'start': 662.2, 'duration': 5.84}, {'text': 'una Ray si quisieran podrían convertir', 'start': 665.68, 'duration': 4.32}, {'text': 'esa variable como sabemos hacer de', 'start': 668.04, 'duration': 5.88}, {'text': 'costumbre stws taray para poder verla de', 'start': 670.0, 'duration': 6.24}, {'text': 'una manera más más amigable est una al', 'start': 673.92, 'duration': 3.919}, {'text': 'lado de otra y no una bajo otra pero a', 'start': 676.24, 'duration': 3.56}, {'text': 'los fines prácticos si aquí tenemos', 'start': 677.839, 'duration': 4.56}, {'text': 'entonces todas las palabras que forman', 'start': 679.8, 'duration': 4.839}, {'text': 'parte de las stop words o lo que está', 'start': 682.399, 'duration': 4.401}, {'text': 'definido dentro del natural Language', 'start': 684.639, 'duration': 5.921}, {'text': 'tool kit en español como stop Word', 'start': 686.8, 'duration': 6.52}, {'text': 'obviamente es una lista muy muy larga si', 'start': 690.56, 'duration': 4.36}, {'text': 'como siempre es complicado recorrerla de', 'start': 693.32, 'duration': 3.68}, {'text': 'este modo Pero bueno lo dejo en ustedes', 'start': 694.92, 'duration': 6.039}, {'text': 'Poder recorrerla De punta a punta bien', 'start': 697.0, 'duration': 6.68}, {'text': 'una vez que tenemos esto lo siguiente', 'start': 700.959, 'duration': 6.281}, {'text': 'sería tokenizar la frase texto si la que', 'start': 703.68, 'duration': 6.44}, {'text': 'teníamos arriba de todo que volvemos ha', 'start': 707.24, 'duration': 4.8}, {'text': 'arriba nuevamente en algunos países los', 'start': 710.12, 'duration': 3.839}, {'text': 'días son muy largos y las noches muy', 'start': 712.04, 'duration': 4.799}, {'text': 'cortas bien Voy a', 'start': 713.959, 'duration': 6.12}, {'text': 'tokenizar esa frase de De qué modo con', 'start': 716.839, 'duration': 6.24}, {'text': 'Word tokenize de texto de la variable', 'start': 720.079, 'duration': 6.081}, {'text': 'texto y voy a poner ese resultado dentro', 'start': 723.079, 'duration': 6.0}, {'text': 'de la variable tokens es decir que en', 'start': 726.16, 'duration': 6.56}, {'text': 'tokens van a estar Qué cosa todas las', 'start': 729.079, 'duration': 5.481}, {'text': 'palabras de esa', 'start': 732.72, 'duration': 4.84}, {'text': 'frase luego lo que voy a hacer va a ser', 'start': 734.56, 'duration': 6.44}, {'text': 'recorrer cada una de esas palabras por', 'start': 737.56, 'duration': 7.16}, {'text': 'eso pongo Word Forward in tokens por', 'start': 741.0, 'duration': 6.56}, {'text': 'cada palabra de cada una de las palabras', 'start': 744.72, 'duration': 4.44}, {'text': 'que están en la colección de token se', 'start': 747.56, 'duration': 2.639}, {'text': 'acuérdense que la colección de token', 'start': 749.16, 'duration': 2.52}, {'text': 'fíjense que ahí me paro y me aparece la', 'start': 750.199, 'duration': 3.76}, {'text': 'ayuda está conformada por tres', 'start': 751.68, 'duration': 7.0}, {'text': 'items bien y luego le pongo como', 'start': 753.959, 'duration': 8.24}, {'text': 'condición If not Word la palabra', 'start': 758.68, 'duration': 7.159}, {'text': 'concretamente in stop Wars con esto', 'start': 762.199, 'duration': 6.0}, {'text': 'resumo por cada palabra que está en', 'start': 765.839, 'duration': 7.041}, {'text': 'tokens pero que no está en la hop Word', 'start': 768.199, 'duration': 6.721}, {'text': 'con lo cual me quedo con las palabras', 'start': 772.88, 'duration': 5.319}, {'text': 'que están fuera de las stop Word y luego', 'start': 774.92, 'duration': 5.64}, {'text': 'imprimo el contenido de esta variable', 'start': 778.199, 'duration': 5.121}, {'text': 'que le he puesto texto ssw como siendo', 'start': 780.56, 'duration': 3.76}, {'text': 'bueno', 'start': 783.32, 'duration': 5.24}, {'text': 'stop texto sin stop Wars Perdón entonces', 'start': 784.32, 'duration': 6.8}, {'text': 'ejecuto esto y fíjense lo que me muestra', 'start': 788.56, 'duration': 4.519}, {'text': 'que es lo que habíamos visto hoy en el', 'start': 791.12, 'duration': 5.839}, {'text': 'ejemplo en la parte teórica en países', 'start': 793.079, 'duration': 8.841}, {'text': 'días largos noches cortas pero yo veo', 'start': 796.959, 'duration': 9.56}, {'text': 'aquí si me voy a las stop Wars y subo un', 'start': 801.92, 'duration': 5.84}, {'text': 'poquito', 'start': 806.519, 'duration': 3.12}, {'text': 'aquí', 'start': 807.76, 'duration': 5.879}, {'text': 'rápidamente veo que n está dentro de las', 'start': 809.639, 'duration': 5.32}, {'text': 'stop', 'start': 813.639, 'duration': 4.961}, {'text': 'Wars Qué pasó que me muestra quién', 'start': 814.959, 'duration': 7.0}, {'text': 'siendo que yo le puse como condición que', 'start': 818.6, 'duration': 5.599}, {'text': 'lo que tenía que estar dentro de texto', 'start': 821.959, 'duration': 5.12}, {'text': 'ssb debían ser aquellas palabras que no', 'start': 824.199, 'duration': 5.721}, {'text': 'están dentro de War Bueno lo que pasa es', 'start': 827.079, 'duration': 5.44}, {'text': 'que como ustedes pueden apreciar aquí en', 'start': 829.92, 'duration': 6.279}, {'text': 'está con la e en mayúscula mientras que', 'start': 832.519, 'duration': 8.24}, {'text': 'en las stop Wars volvemos a aquí en está', 'start': 836.199, 'duration': 7.56}, {'text': 'como todas las stop Wars en minúscula', 'start': 840.759, 'duration': 4.64}, {'text': 'entonces lo que tenemos que hacer es', 'start': 843.759, 'duration': 4.2}, {'text': 'reconfigurar lo que hicimos Recién con', 'start': 845.399, 'duration': 4.12}, {'text': 'una instrucción', 'start': 847.959, 'duration': 4.601}, {'text': 'previa texto igual a texto pun l también', 'start': 849.519, 'duration': 4.481}, {'text': 'lo vimos en la teoría esto y también es', 'start': 852.56, 'duration': 3.24}, {'text': 'una instrucción de python un método de', 'start': 854.0, 'duration': 3.279}, {'text': 'python que ya lo conocen bastante con lo', 'start': 855.8, 'duration': 3.56}, {'text': 'cual con esto voy a convertir toda la', 'start': 857.279, 'duration': 4.841}, {'text': 'frase De punta a punta en minúscula y', 'start': 859.36, 'duration': 4.839}, {'text': 'voy a volver a ejecutar las mismas tres', 'start': 862.12, 'duration': 4.159}, {'text': 'líneas que ejecutamos antes y voy a ver', 'start': 864.199, 'duration': 4.681}, {'text': 'que ahora van a aparecer la misma toen', 'start': 866.279, 'duration': 4.881}, {'text': 'ación es decir la misma eh el mismo', 'start': 868.88, 'duration': 4.6}, {'text': 'arreglo el mismo aray que tiene aquellas', 'start': 871.16, 'duration': 4.08}, {'text': 'palabras tokenizadas pero que no están', 'start': 873.48, 'duration': 4.479}, {'text': 'en el Word en este caso sin la palabra', 'start': 875.24, 'duration': 5.88}, {'text': 'en que había salido antes bien con esto', 'start': 877.959, 'duration': 5.641}, {'text': 'Terminamos el primer lab de este', 'start': 881.12, 'duration': 4.88}, {'text': '[Música]', 'start': 883.6, 'duration': 4.72}, {'text': 'curso los conceptos que tenemos que ver', 'start': 886.0, 'duration': 5.199}, {'text': 'a continuación son estos dos stemin y', 'start': 888.32, 'duration': 4.72}, {'text': 'lematización en realidad tienen', 'start': 891.199, 'duration': 3.401}, {'text': 'propósitos similares pero tienen', 'start': 893.04, 'duration': 3.96}, {'text': 'técnicas diferentes de qué se trata esto', 'start': 894.6, 'duration': 4.08}, {'text': 'en realidad vamos a tener en cuenta al', 'start': 897.0, 'duration': 3.36}, {'text': 'algunas cuestiones antes de entrar en', 'start': 898.68, 'duration': 4.12}, {'text': 'las características de cada uno de ellos', 'start': 900.36, 'duration': 5.279}, {'text': 'las palabras similares se tratan como', 'start': 902.8, 'duration': 6.08}, {'text': 'entidades separadas es decir corre', 'start': 905.639, 'duration': 6.56}, {'text': 'corriendo o corre son palabras muy', 'start': 908.88, 'duration': 5.6}, {'text': 'similares pero habitualmente se tratan', 'start': 912.199, 'duration': 4.241}, {'text': 'por ser palabras distintas con entidades', 'start': 914.48, 'duration': 5.039}, {'text': 'separadas las mismas en realidad van a', 'start': 916.44, 'duration': 4.72}, {'text': 'ser representadas por vectores que van a', 'start': 919.519, 'duration': 4.0}, {'text': 'estar muy cerca a unos de otros por qué', 'start': 921.16, 'duration': 4.0}, {'text': 'porque las tres palabras tienen un', 'start': 923.519, 'duration': 3.801}, {'text': 'sentido similar o un sentido que', 'start': 925.16, 'duration': 4.799}, {'text': 'asociativamente es parecido pero van a', 'start': 927.32, 'duration': 4.16}, {'text': 'estar representadas por vectores', 'start': 929.959, 'duration': 3.68}, {'text': 'diferentes esto lo teníamos en la imagen', 'start': 931.48, 'duration': 4.12}, {'text': 'que vimos hace un rato vamos a ver un', 'start': 933.639, 'duration': 4.401}, {'text': 'poco ella para poder recuperar este', 'start': 935.6, 'duration': 4.599}, {'text': 'concepto que está aquí recuerdan este', 'start': 938.04, 'duration': 4.64}, {'text': 'gráfico bueno supongamos que esto de', 'start': 940.199, 'duration': 5.521}, {'text': 'correr corriendo corre fueran estos', 'start': 942.68, 'duration': 5.599}, {'text': 'vectores que probablemente justamente', 'start': 945.72, 'duration': 4.599}, {'text': 'como son palabras que tienen un sentido', 'start': 948.279, 'duration': 6.36}, {'text': 'muy similar estén cerca estos vectores', 'start': 950.319, 'duration': 6.08}, {'text': 'eso va a ser justamente una', 'start': 954.639, 'duration': 4.64}, {'text': 'representación vectorial que representa', 'start': 956.399, 'duration': 5.12}, {'text': 'esa realidad de palabras similares pero', 'start': 959.279, 'duration': 5.281}, {'text': 'concretamente yo voy a estar teniendo un', 'start': 961.519, 'duration': 6.521}, {'text': 'espacio con tres dimensiones Y eso es lo', 'start': 964.56, 'duration': 6.199}, {'text': 'que trato de evitar con el steaming y la', 'start': 968.04, 'duration': 5.68}, {'text': 'lematización por eso como dice aquí lo', 'start': 970.759, 'duration': 5.08}, {'text': 'que vimos recién genera una gran', 'start': 973.72, 'duration': 4.479}, {'text': 'dimensionalidad la cual se podría', 'start': 975.839, 'duration': 5.201}, {'text': 'reducir si utilizáramos una misma raíz', 'start': 978.199, 'duration': 5.32}, {'text': 'de esas palabras para representarlas', 'start': 981.04, 'duration': 5.279}, {'text': 'todas del mismo modo es decir correr', 'start': 983.519, 'duration': 5.8}, {'text': 'corriendo y corre tienen una palabra', 'start': 986.319, 'duration': 5.52}, {'text': 'raíz que puede ser asociada a las tres y', 'start': 989.319, 'duration': 4.801}, {'text': 'de esa manera representar las tres con', 'start': 991.839, 'duration': 4.44}, {'text': 'una palabra que sea representativa y no', 'start': 994.12, 'duration': 4.519}, {'text': 'con las tres por separada para eso', 'start': 996.279, 'duration': 4.641}, {'text': 'existen dos técnicas que son stemin y', 'start': 998.639, 'duration': 4.44}, {'text': 'lematización y vamos a ver justamente', 'start': 1000.92, 'duration': 4.52}, {'text': 'cada una de ellas de qué se', 'start': 1003.079, 'duration': 5.32}, {'text': 'trata el stemin es una técnica que', 'start': 1005.44, 'duration': 5.319}, {'text': 'elimina los sufijos de una palabra por', 'start': 1008.399, 'duration': 5.721}, {'text': 'ejemplo tengo caminar y caminando ambas', 'start': 1010.759, 'duration': 6.08}, {'text': 'palabras se van a transformar en camín', 'start': 1014.12, 'duration': 5.44}, {'text': 'es decir toma lo que tienen en común', 'start': 1016.839, 'duration': 5.081}, {'text': 'ambas palabras y a la primera le quita', 'start': 1019.56, 'duration': 6.04}, {'text': 'el ar y a la segunda le quita el and con', 'start': 1021.92, 'duration': 6.919}, {'text': 'lo cual de dos palabras paso a tener una', 'start': 1025.6, 'duration': 6.12}, {'text': 'de dos dimensiones paso a una la', 'start': 1028.839, 'duration': 5.6}, {'text': 'lematización busca un objetivo similar', 'start': 1031.72, 'duration': 4.959}, {'text': 'pero con una una técnica o una modalidad', 'start': 1034.439, 'duration': 4.6}, {'text': 'diferente la lematización lo que hace es', 'start': 1036.679, 'duration': 6.721}, {'text': 'Buscar la palabra raíz u origen de esas', 'start': 1039.039, 'duration': 6.361}, {'text': 'palabras que tienen un sentido similar', 'start': 1043.4, 'duration': 5.96}, {'text': 'por ejemplo caminar caminando Caminaré', 'start': 1045.4, 'duration': 6.84}, {'text': 'camino se transforman en que su palabra', 'start': 1049.36, 'duration': 6.6}, {'text': 'raíz es caminar aquí no quita una parte', 'start': 1052.24, 'duration': 6.559}, {'text': 'de la palabra para llegar a lo que sería', 'start': 1055.96, 'duration': 4.8}, {'text': 'una palabra resumida quitando lo que', 'start': 1058.799, 'duration': 3.681}, {'text': 'decíamos recién los sufijos como hace el', 'start': 1060.76, 'duration': 5.4}, {'text': 'steaming sino que busca la palabra raíz', 'start': 1062.48, 'duration': 6.04}, {'text': 'de esas cuatro palabras esto obviamente', 'start': 1066.16, 'duration': 4.72}, {'text': 'es un proceso que es más lento porque lo', 'start': 1068.52, 'duration': 4.76}, {'text': 'que hace el St Es simplemente recortar', 'start': 1070.88, 'duration': 4.159}, {'text': 'parte de una palabra aquí lo que tiene', 'start': 1073.28, 'duration': 3.519}, {'text': 'que hacer es tomar todas esas palabras', 'start': 1075.039, 'duration': 3.081}, {'text': 'tod Ese Conjunto de palabras en este', 'start': 1076.799, 'duration': 4.12}, {'text': 'caso de cuatro y buscar cuál es la', 'start': 1078.12, 'duration': 4.76}, {'text': 'palabra raíz que representa esas cuatro', 'start': 1080.919, 'duration': 4.0}, {'text': 'Pero nuevamente el objetivo es el mismo', 'start': 1082.88, 'duration': 4.36}, {'text': 'porque paso de tener en este caso cuatro', 'start': 1084.919, 'duration': 5.111}, {'text': 'dimensiones a solamente una', 'start': 1087.24, 'duration': 3.88}, {'text': '[Música]', 'start': 1090.03, 'duration': 4.33}, {'text': 'dimensión al igual que hace un rato esto', 'start': 1091.12, 'duration': 5.0}, {'text': 'lo vamos a ver en la práctica por eso', 'start': 1094.36, 'duration': 3.96}, {'text': 'existe otro archivo de colab que tienen', 'start': 1096.12, 'duration': 4.28}, {'text': 'en el campus virtual que se llama lab', 'start': 1098.32, 'duration': 5.12}, {'text': 'pnl 2 y justamente me da un ejemplo de', 'start': 1100.4, 'duration': 6.36}, {'text': 'streaming y de lematización vamos hacia', 'start': 1103.44, 'duration': 5.68}, {'text': 'ello bien est vamos ahora nuevamente en', 'start': 1106.76, 'duration': 5.48}, {'text': 'colap pero ahora en el la pnl 2 en este', 'start': 1109.12, 'duration': 4.76}, {'text': 'caso el tema es stemin como decíamos', 'start': 1112.24, 'duration': 3.16}, {'text': 'recién y lo primero que vamos a hacer es', 'start': 1113.88, 'duration': 4.4}, {'text': 'importar bueno natural Language toolkit', 'start': 1115.4, 'duration': 5.56}, {'text': 'y vamos a hacer un Download parecido a', 'start': 1118.28, 'duration': 4.24}, {'text': 'lo que hicimos En el lab anterior pero', 'start': 1120.96, 'duration': 2.959}, {'text': 'ahora de', 'start': 1122.52, 'duration': 4.48}, {'text': 'wordnet Por qué wordnet cuando Antes', 'start': 1123.919, 'duration': 7.0}, {'text': 'había elegido Punk y stop Wars bueno en', 'start': 1127.0, 'duration': 6.36}, {'text': 'el caso de punkt tenía que ver con la', 'start': 1130.919, 'duration': 4.681}, {'text': 'tokenización y en el caso que nos', 'start': 1133.36, 'duration': 4.92}, {'text': 'ocupaba en el primer lab yo quería sola', 'start': 1135.6, 'duration': 5.92}, {'text': 'ente poder tokenizar esta frase es decir', 'start': 1138.28, 'duration': 5.04}, {'text': 'Tomar las palabras separadas de esta', 'start': 1141.52, 'duration': 4.12}, {'text': 'frase y las stopwords eran con el', 'start': 1143.32, 'duration': 3.76}, {'text': 'propósito que dimos recién que tenía que', 'start': 1145.64, 'duration': 3.56}, {'text': 'ver con la posibilidad de quitar de esa', 'start': 1147.08, 'duration': 5.719}, {'text': 'frase las stws en este caso la el', 'start': 1149.2, 'duration': 5.68}, {'text': 'stemming y la lematización se trata de', 'start': 1152.799, 'duration': 5.721}, {'text': 'poder inducir a que la inteligencia me', 'start': 1154.88, 'duration': 5.72}, {'text': 'permita en algunos casos quitar el', 'start': 1158.52, 'duration': 4.36}, {'text': 'sufijo y en otros casos encontrar la', 'start': 1160.6, 'duration': 4.28}, {'text': 'palabra raíz y para eso necesita como', 'start': 1162.88, 'duration': 5.56}, {'text': 'referencia una librería que contenga el', 'start': 1164.88, 'duration': 5.44}, {'text': 'vocabulario luego el vocabulario yo lo', 'start': 1168.44, 'duration': 4.239}, {'text': 'puedo configurar para que esté en un', 'start': 1170.32, 'duration': 4.16}, {'text': 'determinado idioma Pero por eso en este', 'start': 1172.679, 'duration': 4.12}, {'text': 'caso particular que se diferencia', 'start': 1174.48, 'duration': 3.8}, {'text': 'claramente de los propósitos del lab', 'start': 1176.799, 'duration': 3.12}, {'text': 'anterior tengo que carrar la librería', 'start': 1178.28, 'duration': 3.8}, {'text': 'wordnet Así que lo primero que hago es', 'start': 1179.919, 'duration': 5.24}, {'text': 'eso y una vez terminado esto lo que voy', 'start': 1182.08, 'duration': 8.44}, {'text': 'a llamar d nltk stem importar snowball', 'start': 1185.159, 'duration': 8.76}, {'text': 'steamer esta librería con la cual voy a', 'start': 1190.52, 'duration': 6.159}, {'text': 'crear una instancia una variable que le', 'start': 1193.919, 'duration': 5.24}, {'text': 'voy a poner steamer instancia a través', 'start': 1196.679, 'duration': 5.281}, {'text': 'justamente snowball steamer configurando', 'start': 1199.159, 'duration': 6.161}, {'text': 'esa instancia de snowball es decir', 'start': 1201.96, 'duration': 5.599}, {'text': 'básicamente lo que va a representar la', 'start': 1205.32, 'duration': 5.16}, {'text': 'acción del steamer en español con lo', 'start': 1207.559, 'duration': 4.961}, {'text': 'cual creo esta variable Y a partir de', 'start': 1210.48, 'duration': 3.559}, {'text': 'eso y justamente con esta variable de', 'start': 1212.52, 'duration': 4.24}, {'text': 'objeto lo que voy a hacer va a ser tomar', 'start': 1214.039, 'duration': 4.361}, {'text': 'tres palabras como las que tomamos', 'start': 1216.76, 'duration': 4.24}, {'text': 'recién como ejemplo y ver el steamer', 'start': 1218.4, 'duration': 4.96}, {'text': 'Cuál es la reducción que hace al quitar', 'start': 1221.0, 'duration': 4.24}, {'text': 'los sufijos de cada una de esas palabras', 'start': 1223.36, 'duration': 4.0}, {'text': 'por eso hago tres prints Cuando pruebo', 'start': 1225.24, 'duration': 5.96}, {'text': 'esto veo que comiendo comer y comió en', 'start': 1227.36, 'duration': 6.04}, {'text': 'los tres casos el steaming lo que hizo', 'start': 1231.2, 'duration': 5.08}, {'text': 'fue quitarle los sufijos y reducirlos a', 'start': 1233.4, 'duration': 4.8}, {'text': 'las palabras que tienen en común la c la', 'start': 1236.28, 'duration': 3.639}, {'text': 'o y la', 'start': 1238.2, 'duration': 4.08}, {'text': 'm bien es el turno ahora de la', 'start': 1239.919, 'duration': 4.401}, {'text': 'lematización en el caso de la', 'start': 1242.28, 'duration': 4.08}, {'text': 'lematización no vamos a usar la librería', 'start': 1244.32, 'duration': 5.0}, {'text': 'nltk que usamos antes para el steaming y', 'start': 1246.36, 'duration': 5.12}, {'text': 'que también usamos en el lav anterior', 'start': 1249.32, 'duration': 4.56}, {'text': 'dado que si bien tiene la herramienta', 'start': 1251.48, 'duration': 3.96}, {'text': 'para hacer la lematización esa', 'start': 1253.88, 'duration': 3.24}, {'text': 'herramienta no está disponible en lengua', 'start': 1255.44, 'duration': 4.44}, {'text': 'castellana por eso vamos a recurrir a la', 'start': 1257.12, 'duration': 5.96}, {'text': 'librería spacy que sí tiene esa opción', 'start': 1259.88, 'duration': 5.64}, {'text': 'de lematización en lengua castellana y', 'start': 1263.08, 'duration': 4.479}, {'text': 'de paso me sirve esto para decirles de', 'start': 1265.52, 'duration': 4.039}, {'text': 'que estamos sumando una librería más', 'start': 1267.559, 'duration': 4.36}, {'text': 'para ese tipo de actividades u otras y', 'start': 1269.559, 'duration': 4.961}, {'text': 'que eso no implica que sean las dos', 'start': 1271.919, 'duration': 4.281}, {'text': 'únicas que existen para este tipo de', 'start': 1274.52, 'duration': 4.279}, {'text': 'tareas en el mundo del nlp pero sí es', 'start': 1276.2, 'duration': 4.44}, {'text': 'importante que tengan presente que son', 'start': 1278.799, 'duration': 4.801}, {'text': 'las dos o dos de las más conocidas el', 'start': 1280.64, 'duration': 5.8}, {'text': 'spacy no viene naturalmente instalado en', 'start': 1283.6, 'duration': 5.48}, {'text': 'python como el nl tk por lo tanto', 'start': 1286.44, 'duration': 5.08}, {'text': 'tenemos que instalarlo para eso usamos', 'start': 1289.08, 'duration': 4.76}, {'text': 'el argumento que ya conocemos el método', 'start': 1291.52, 'duration': 3.96}, {'text': 'que ya conocemos la herramienta de', 'start': 1293.84, 'duration': 5.28}, {'text': 'python que es pip pip install spacy y el', 'start': 1295.48, 'duration': 6.12}, {'text': 'menq básicamente es para que no muestre', 'start': 1299.12, 'duration': 3.84}, {'text': 'una serie de información que tiene que', 'start': 1301.6, 'duration': 3.64}, {'text': 'ver con la instalación y luego lo que', 'start': 1302.96, 'duration': 5.44}, {'text': 'tengo que instalar es el diccionario o', 'start': 1305.24, 'duration': 5.96}, {'text': 'el conjunto de palabras justamente que', 'start': 1308.4, 'duration': 5.6}, {'text': 'viene para usar el spacy en castellano', 'start': 1311.2, 'duration': 4.959}, {'text': 'con esta frase que está aquí Bueno esto', 'start': 1314.0, 'duration': 3.64}, {'text': 'tarda mucho yo lo tengo instalado para', 'start': 1316.159, 'duration': 3.281}, {'text': 'no per tiempo lo vamos a considerar como', 'start': 1317.64, 'duration': 4.24}, {'text': 'que ya está pero esto es simplemente', 'start': 1319.44, 'duration': 5.119}, {'text': 'hacerle clic al al Play de cada de cada', 'start': 1321.88, 'duration': 4.799}, {'text': 'una de estas celdas y está instalado por', 'start': 1324.559, 'duration': 3.561}, {'text': 'un lado del spacey y por el otro lado', 'start': 1326.679, 'duration': 3.641}, {'text': 'del dicionario bien Vamos al código', 'start': 1328.12, 'duration': 4.0}, {'text': 'concretamente y lo primero que hago es', 'start': 1330.32, 'duration': 4.839}, {'text': 'importar spacey luego lo que voy a hacer', 'start': 1332.12, 'duration': 5.439}, {'text': 'a continuación va a ser Perdón me qu un', 'start': 1335.159, 'duration': 4.561}, {'text': 'error aquí volvemos a la línea lo que', 'start': 1337.559, 'duration': 5.921}, {'text': 'vamos a hacer a continuación es lobar de', 'start': 1339.72, 'duration': 6.8}, {'text': 'spacy es decir cargar el dicionario de', 'start': 1343.48, 'duration': 5.88}, {'text': 'Castellano y lo voy a cargar dentro de', 'start': 1346.52, 'duration': 5.639}, {'text': 'una variable que se le voy a poner nlp', 'start': 1349.36, 'duration': 5.08}, {'text': 'la cual obviamente va a contener todo', 'start': 1352.159, 'duration': 4.4}, {'text': 'este conjunto de palabras que me ofrece', 'start': 1354.44, 'duration': 6.2}, {'text': 'spacy para la lematización en castellano', 'start': 1356.559, 'duration': 6.24}, {'text': 'paso Seguido lo que voy a hacer es usar', 'start': 1360.64, 'duration': 4.76}, {'text': 'justamente esa variable nlp para hacer', 'start': 1362.799, 'duration': 4.921}, {'text': 'una tokenización de una frase una frase', 'start': 1365.4, 'duration': 4.24}, {'text': 'que en realidad es un poco ficticia pero', 'start': 1367.72, 'duration': 4.4}, {'text': 'tiene que ver con rápidamente demostrar', 'start': 1369.64, 'duration': 4.76}, {'text': 'de qué se trata la lematización y Cómo', 'start': 1372.12, 'duration': 3.6}, {'text': 'podemos visualizar los resultados de', 'start': 1374.4, 'duration': 3.8}, {'text': 'ella Por ende esa frase dice comiendo', 'start': 1375.72, 'duration': 4.28}, {'text': 'comer comió evidentemente no tiene un', 'start': 1378.2, 'duration': 3.599}, {'text': 'sentido en la lengua castellana Pero', 'start': 1380.0, 'duration': 3.52}, {'text': 'insisto a los fines de esta mini', 'start': 1381.799, 'duration': 3.88}, {'text': 'práctica viene bien con lo cual en', 'start': 1383.52, 'duration': 5.68}, {'text': 'tokens gracias a nlp lo que voy a tener', 'start': 1385.679, 'duration': 5.921}, {'text': 'justamente es esta frase separada entre', 'start': 1389.2, 'duration': 5.04}, {'text': 'tokens comiendo comer y comendo y Por', 'start': 1391.6, 'duration': 5.6}, {'text': 'ende con este for voy a recorrer for', 'start': 1394.24, 'duration': 5.4}, {'text': 'token in tokens es decir por cada uno de', 'start': 1397.2, 'duration': 3.68}, {'text': 'esos elementos que están dentro de', 'start': 1399.64, 'duration': 2.96}, {'text': 'tokens por cada uno lo que voy a hacer', 'start': 1400.88, 'duration': 3.84}, {'text': 'es arme un String digamos para que se', 'start': 1402.6, 'duration': 3.4}, {'text': 'vea por pantalla', 'start': 1404.72, 'duration': 4.76}, {'text': 'claramente texto dos puntos token pun', 'start': 1406.0, 'duration': 5.32}, {'text': 'text es decir el token ese mismo', 'start': 1409.48, 'duration': 3.88}, {'text': 'comiendo por ejemplo en el caso y luego', 'start': 1411.32, 'duration': 5.599}, {'text': 'lema Qué sería Cuál es la lematización o', 'start': 1413.36, 'duration': 5.88}, {'text': 'cuál es la palabra resultante de aplicar', 'start': 1416.919, 'duration': 5.401}, {'text': 'la lematización sobre comiendo luego', 'start': 1419.24, 'duration': 5.439}, {'text': 'sobre comer y luego sobrecomo acuérdense', 'start': 1422.32, 'duration': 4.76}, {'text': 'que la lización no quita el sufijo como', 'start': 1424.679, 'duration': 4.36}, {'text': 'el steaming sino que busca una palabra', 'start': 1427.08, 'duration': 4.68}, {'text': 'raíz por eso cuando ejecuto esto me', 'start': 1429.039, 'duration': 5.481}, {'text': 'muestra que para comiendo para comer y', 'start': 1431.76, 'duration': 5.6}, {'text': 'para comió existe una palabra raíz única', 'start': 1434.52, 'duration': 4.56}, {'text': 'que seama se llama comer con lo cual', 'start': 1437.36, 'duration': 3.72}, {'text': 'estoy reduciendo esta posible', 'start': 1439.08, 'duration': 3.719}, {'text': 'dimensionalidad de vectores de tres', 'start': 1441.08, 'duration': 4.64}, {'text': 'palabras a una', 'start': 1442.799, 'duration': 2.921}, {'text': 'sola algunas cuestiones que hay que', 'start': 1446.0, 'duration': 4.24}, {'text': 'tener en cuenta con la lematización que', 'start': 1448.159, 'duration': 3.921}, {'text': 'recién referenciamos Es que la', 'start': 1450.24, 'duration': 4.28}, {'text': 'lematización puede ser más efectiva que', 'start': 1452.08, 'duration': 5.839}, {'text': 'el stemin pero su gasto computacional es', 'start': 1454.52, 'duration': 5.92}, {'text': 'mucho mayor por qué Porque el uso de la', 'start': 1457.919, 'duration': 4.481}, {'text': 'lematización requiere de una etiquetado', 'start': 1460.44, 'duration': 4.239}, {'text': 'previo ya que hay que encontrar una', 'start': 1462.4, 'duration': 4.639}, {'text': 'palabra que represente a un grupo tal', 'start': 1464.679, 'duration': 4.561}, {'text': 'cual veíamos en el ejemplo de reciente', 'start': 1467.039, 'duration': 4.561}, {'text': 'Por ende hay que hacer un trabajo extra', 'start': 1469.24, 'duration': 3.84}, {'text': 'que no existe en el estamiento', 'start': 1471.6, 'duration': 4.28}, {'text': 'simplemente recorto la palabra si veo', 'start': 1473.08, 'duration': 5.44}, {'text': 'aquí estos ejemplos donde este cuadro', 'start': 1475.88, 'duration': 4.519}, {'text': 'que está a la izquierda representa una', 'start': 1478.52, 'duration': 4.879}, {'text': 'lematización comiendo comer y comó se', 'start': 1480.399, 'duration': 6.28}, {'text': 'sintetizan en una palabra comer que es', 'start': 1483.399, 'duration': 5.961}, {'text': 'una etiqueta con la cual está', 'start': 1486.679, 'duration': 5.48}, {'text': 'etiquetando estas tres palabras comiendo', 'start': 1489.36, 'duration': 5.36}, {'text': 'comer y comió con una etiqueta comer en', 'start': 1492.159, 'duration': 4.52}, {'text': 'los tres casos por el contrario en el', 'start': 1494.72, 'duration': 4.28}, {'text': 'caso del stemin con este ejemplo que', 'start': 1496.679, 'duration': 4.88}, {'text': 'está aquí yo lo que estoy haciendo es', 'start': 1499.0, 'duration': 5.72}, {'text': 'simplemente sacar el sufijo es decir', 'start': 1501.559, 'duration': 7.081}, {'text': 'comiendo comer y comió tienen en común', 'start': 1504.72, 'duration': 6.36}, {'text': 'las tres primeras letras con lo cual', 'start': 1508.64, 'duration': 4.6}, {'text': 'aquí el gasto computacional al no tener', 'start': 1511.08, 'duration': 4.16}, {'text': 'que buscar esta palabra raíz como el', 'start': 1513.24, 'duration': 4.08}, {'text': 'caso de comer y etiquetar cada una de', 'start': 1515.24, 'duration': 4.559}, {'text': 'esas palabras con esa etiqueta es', 'start': 1517.32, 'duration': 5.28}, {'text': 'obviamente en el caso del stem mucho', 'start': 1519.799, 'duration': 5.441}, {'text': 'menor el gasto computacional y Por ende', 'start': 1522.6, 'duration': 7.079}, {'text': 'el algoritmo es más rápido', 'start': 1525.24, 'duration': 4.439}, {'text': 'para cerrar el tema St y lematización', 'start': 1530.08, 'duration': 4.199}, {'text': 'vamos a poner foco sobre algunas', 'start': 1532.08, 'duration': 4.04}, {'text': 'aplicaciones en donde se pueden aplicar', 'start': 1534.279, 'duration': 5.88}, {'text': 'valga la redundancia estas dos', 'start': 1536.12, 'duration': 4.039}, {'text': 'técnicas en principio hay empresas que', 'start': 1540.559, 'duration': 5.12}, {'text': 'usan asistentes virtuales o chatbox por', 'start': 1543.0, 'duration': 5.399}, {'text': 'ejemplo Amazon con Alexa o empresas que', 'start': 1545.679, 'duration': 4.961}, {'text': 'proporcionan servicios al cliente que', 'start': 1548.399, 'duration': 4.241}, {'text': 'utilizan la lematización y el stemming', 'start': 1550.64, 'duration': 3.56}, {'text': 'para comprender las consultas de los', 'start': 1552.64, 'duration': 4.039}, {'text': 'usuarios con mayor precisión a ver por', 'start': 1554.2, 'duration': 4.24}, {'text': 'ejemplo si un usuario pregunta al', 'start': 1556.679, 'duration': 3.801}, {'text': 'chatbox de una empresa que tenga', 'start': 1558.44, 'duration': 3.68}, {'text': 'atención al cliente Dónde está su', 'start': 1560.48, 'duration': 4.4}, {'text': 'paquete el chatbox Debería ser capaz de', 'start': 1562.12, 'duration': 5.159}, {'text': 'entender la pregunta así como también', 'start': 1564.88, 'duration': 5.44}, {'text': 'otra pregunta parecida a esa en el', 'start': 1567.279, 'duration': 5.081}, {'text': 'análisis de sentimiento por ejemplo si', 'start': 1570.32, 'duration': 4.04}, {'text': 'vamos a monitorear Twitter con las redes', 'start': 1572.36, 'duration': 3.799}, {'text': 'sociales y alguien twitea por ejemplo', 'start': 1574.36, 'duration': 4.96}, {'text': 'estoy enfadado con la empresa Nno o XX', 'start': 1576.159, 'duration': 4.921}, {'text': 'se podría entender que enfadado y', 'start': 1579.32, 'duration': 4.76}, {'text': 'enojado o irritado son sentimientos', 'start': 1581.08, 'duration': 4.959}, {'text': 'similares y por lo tanto deben ser', 'start': 1584.08, 'duration': 3.64}, {'text': 'tratados de la misma manera para', 'start': 1586.039, 'duration': 4.52}, {'text': 'análisis entonces una lematización en', 'start': 1587.72, 'duration': 5.24}, {'text': 'este caso podría ser que cada vez que', 'start': 1590.559, 'duration': 5.401}, {'text': 'diga enfadado enojado o irritado todas', 'start': 1592.96, 'duration': 5.839}, {'text': 'tengan la misma base raíz que sería un', 'start': 1595.96, 'duration': 4.959}, {'text': 'sentimiento de enojo también con los', 'start': 1598.799, 'duration': 4.441}, {'text': 'motores de búsqueda Ocurre algo parecido', 'start': 1600.919, 'duration': 4.12}, {'text': 'a lo que decíamos en el caso de los', 'start': 1603.24, 'duration': 4.76}, {'text': 'chatbox dado que una consulta expresada', 'start': 1605.039, 'duration': 5.481}, {'text': 'de varias formas diferentes debe dar el', 'start': 1608.0, 'duration': 4.12}, {'text': 'mismo resultado de la búsqueda', 'start': 1610.52, 'duration': 3.48}, {'text': 'zapatillas para correr en la montaña', 'start': 1612.12, 'duration': 3.799}, {'text': 'zapatillas de treking zapatillas de en', 'start': 1614.0, 'duration': 4.919}, {'text': 'senderismo etcétera', 'start': 1615.919, 'duration': 4.721}, {'text': 'otro caso son las empresas que tienen', 'start': 1618.919, 'duration': 3.561}, {'text': 'sistema de recomendación Como por', 'start': 1620.64, 'duration': 5.159}, {'text': 'ejemplo Netflix Spotify Amazon u otras', 'start': 1622.48, 'duration': 6.12}, {'text': 'en donde utilizan la lematización y el', 'start': 1625.799, 'duration': 5.12}, {'text': 'stemming para mejorar la precisión de la', 'start': 1628.6, 'duration': 4.72}, {'text': 'recomendación a ver por ejemplo si un', 'start': 1630.919, 'duration': 4.64}, {'text': 'usuario Busca películas de acción', 'start': 1633.32, 'duration': 4.239}, {'text': 'debería Netflix ser capaz de entregar', 'start': 1635.559, 'duration': 4.48}, {'text': 'películas de guerra o policiales es', 'start': 1637.559, 'duration': 4.72}, {'text': 'decir que tengan que ver con películas', 'start': 1640.039, 'duration': 4.52}, {'text': 'de acción finalmente también se usa', 'start': 1642.279, 'duration': 4.201}, {'text': 'mucho en la publicidad online por', 'start': 1644.559, 'duration': 3.881}, {'text': 'ejemplo para hacer etiquetado en redes', 'start': 1646.48, 'duration': 4.48}, {'text': 'sociales a ver si queremos hacer una', 'start': 1648.44, 'duration': 4.32}, {'text': 'publicidad y queremos vender celulares', 'start': 1650.96, 'duration': 4.28}, {'text': 'por ejemplo o algún accesorio para gente', 'start': 1652.76, 'duration': 4.2}, {'text': 'que le gusta esa tecnología o convive', 'start': 1655.24, 'duration': 3.88}, {'text': 'con esa tecnología es posible que esta', 'start': 1656.96, 'duration': 4.439}, {'text': 'empresa me ponga anuncios no solo con la', 'start': 1659.12, 'duration': 4.679}, {'text': 'palabra celulares sino también con un', 'start': 1661.399, 'duration': 5.481}, {'text': 'disminutivo popular como celus o una', 'start': 1663.799, 'duration': 5.641}, {'text': 'denominación más formal como smartphones', 'start': 1666.88, 'duration': 4.88}, {'text': 'o cualquier denominación con palabras', 'start': 1669.44, 'duration': 4.839}, {'text': 'similares que básicamente representen lo', 'start': 1671.76, 'duration': 4.88}, {'text': 'mismo Hemos llegado al final de esta', 'start': 1674.279, 'duration': 4.041}, {'text': 'clase', 'start': 1676.64, 'duration': 4.879}, {'text': 'nos vemos en la próxima', 'start': 1678.32, 'duration': 3.199}, {'text': '[Música]', 'start': 1681.62, 'duration': 3.23}, {'text': 'clase', 'start': 1685.399, 'duration': 3.0}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Leer y mostrar el contenido del archivo JSON guardado\n",
        "#filename=\"/content/prueba6.json\"\n",
        "with open(f'{filename}.json', 'r', encoding='utf-8') as json_file:\n",
        "    contenido_json = json.load(json_file)\n",
        "    print(\"Contenido del archivo:\")\n",
        "    print(contenido_json)"
      ],
      "metadata": {
        "id": "1NNiFQ5BWDEa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec01fe47-1632-49f8-a048-72e809cd7068"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contenido del archivo:\n",
            "[{'text': '[Música]', 'start': 0.0, 'duration': 3.04}, {'text': 'Esta es la segunda parte de la clase', 'start': 1.199, 'duration': 6.011}, {'text': 'número 25 te invito a empezar con', 'start': 3.04, 'duration': 25.92}, {'text': '[Música]', 'start': 7.21, 'duration': 23.0}, {'text': 'ella', 'start': 28.96, 'duration': 9.269}, {'text': '[Música]', 'start': 30.21, 'duration': 8.019}, {'text': 'el siguiente tema que tenemos que ver es', 'start': 38.399, 'duration': 4.721}, {'text': 'la tokenización y vamos rápidamente a', 'start': 40.399, 'duration': 4.281}, {'text': 'tratar de entender Qué es la', 'start': 43.12, 'duration': 4.279}, {'text': 'tokenización la tokenización es dividir', 'start': 44.68, 'duration': 5.8}, {'text': 'un texto en tokens los tokens son las', 'start': 47.399, 'duration': 5.96}, {'text': 'unidades individuales de un texto por lo', 'start': 50.48, 'duration': 5.8}, {'text': 'general eh van a ser palabras pero en', 'start': 53.359, 'duration': 4.641}, {'text': 'realidad la tokenización puede dividir', 'start': 56.28, 'duration': 4.04}, {'text': 'el texto en otras unidades que no sean', 'start': 58.0, 'duration': 5.28}, {'text': 'palabras aquí tengo un ejemplo basado en', 'start': 60.32, 'duration': 6.24}, {'text': 'python donde tengo un texto Hola mundo', 'start': 63.28, 'duration': 5.479}, {'text': 'coma Buenos días dentro de una variable', 'start': 66.56, 'duration': 4.32}, {'text': 'que se llama texto y luego lo que hago', 'start': 68.759, 'duration': 4.641}, {'text': 'justamente es aplicar el método split', 'start': 70.88, 'duration': 4.279}, {'text': 'que ustedes ya lo conocen por python que', 'start': 73.4, 'duration': 4.16}, {'text': 'lo que hace es dividir justamente un', 'start': 75.159, 'duration': 6.161}, {'text': 'texto en palabras y lo coloca dentro de', 'start': 77.56, 'duration': 5.199}, {'text': 'una variable que le he dado llamar', 'start': 81.32, 'duration': 3.96}, {'text': 'tokens y luego hago un PR de tokens con', 'start': 82.759, 'duration': 4.4}, {'text': 'lo cual lo que veo es que me sale la', 'start': 85.28, 'duration': 4.24}, {'text': 'palabra que tiene perdón la frase que', 'start': 87.159, 'duration': 4.64}, {'text': 'tiene tiene cuatro palabras con cada una', 'start': 89.52, 'duration': 4.279}, {'text': 'de sus palabras en una Ray', 'start': 91.799, 'duration': 3.561}, {'text': 'individualmente', 'start': 93.799, 'duration': 4.121}, {'text': 'identificadas fíjense que hay algo muy', 'start': 95.36, 'duration': 4.719}, {'text': 'importante aquí que en el caso de olola', 'start': 97.92, 'duration': 4.96}, {'text': 'y en el caso de mundo hay una diferencia', 'start': 100.079, 'duration': 5.08}, {'text': 'mundo tiene una coma y eso lo toma como', 'start': 102.88, 'duration': 4.76}, {'text': 'parte de la palabra y Díaz que es la', 'start': 105.159, 'duration': 4.481}, {'text': 'frase final tiene dos signos de', 'start': 107.64, 'duration': 3.64}, {'text': 'exclamación que también los toma como', 'start': 109.64, 'duration': 3.0}, {'text': 'parte de la palabra Bueno eso es parte', 'start': 111.28, 'duration': 2.479}, {'text': 'de lo que vamos a tener que empezar a', 'start': 112.64, 'duration': 4.68}, {'text': 'ver más adelante de si estas estas estos', 'start': 113.759, 'duration': 6.121}, {'text': 'separadores o estas expresiones que no', 'start': 117.32, 'duration': 4.96}, {'text': 'conforman una palabra del abecedario las', 'start': 119.88, 'duration': 4.76}, {'text': 'voy a querer juntar con la palabra las', 'start': 122.28, 'duration': 4.96}, {'text': 'voy a poder tratarlas como un token', 'start': 124.64, 'duration': 4.28}, {'text': 'aparte o simplemente voy a querer', 'start': 127.24, 'duration': 3.519}, {'text': 'prescindir de ellas que ya vamos a ver', 'start': 128.92, 'duration': 3.44}, {'text': 'más adelante que en realidad la', 'start': 130.759, 'duration': 3.081}, {'text': 'interpretación que se hace a través del', 'start': 132.36, 'duration': 4.4}, {'text': 'nlp muchas veces puede prescindir de', 'start': 133.84, 'duration': 6.22}, {'text': 'estos signos sin perder calidad de', 'start': 136.76, 'duration': 6.28}, {'text': '[Música]', 'start': 140.06, 'duration': 5.539}, {'text': 'interpretación como dijimos recién en la', 'start': 143.04, 'duration': 4.32}, {'text': 'evolución de la toca haciendo un', 'start': 145.599, 'duration': 3.681}, {'text': 'análisis mucho más fino del proceso', 'start': 147.36, 'duration': 3.959}, {'text': 'tenemos formas diferentes de tokenizar', 'start': 149.28, 'duration': 3.8}, {'text': 'en principio basado en palabras lo más', 'start': 151.319, 'duration': 4.401}, {'text': 'tradicional lo más común auto moto bueno', 'start': 153.08, 'duration': 4.48}, {'text': 'el elemento que sea representativo de', 'start': 155.72, 'duration': 4.2}, {'text': 'una palabra de un texto basada en', 'start': 157.56, 'duration': 5.84}, {'text': 'caracteres puedo tomar letras o números', 'start': 159.92, 'duration': 5.52}, {'text': 'o expresiones como la roba o lo que', 'start': 163.4, 'duration': 3.839}, {'text': 'debos recién una coma o un signo de', 'start': 165.44, 'duration': 4.36}, {'text': 'admiración o basado en su palabras Es', 'start': 167.239, 'duration': 5.201}, {'text': 'decir por aquí tengo una palabra que', 'start': 169.8, 'duration': 4.799}, {'text': 'está conformada por otras dos o que se', 'start': 172.44, 'duration': 3.6}, {'text': 'puede subdividir por el sentido que', 'start': 174.599, 'duration': 4.241}, {'text': 'tienen otras dos contraataque en contra', 'start': 176.04, 'duration': 4.32}, {'text': 'o ataque', 'start': 178.84, 'duration': 3.52}, {'text': 'bien consideraciones a tener presente un', 'start': 180.36, 'duration': 4.12}, {'text': 'poco lo que repasamos recién diferentes', 'start': 182.36, 'duration': 4.2}, {'text': 'casos de letra es decir tenemos letras', 'start': 184.48, 'duration': 3.6}, {'text': 'que tienen caracteres complicados como', 'start': 186.56, 'duration': 3.319}, {'text': 'puede ser un tilde una diéresis depende', 'start': 188.08, 'duration': 4.159}, {'text': 'del lenguaje que se trate y justamente', 'start': 189.879, 'duration': 3.761}, {'text': 'lo que tengo que tomar como criterio es', 'start': 192.239, 'duration': 4.761}, {'text': 'si voy a utilizar eso o no en el proceso', 'start': 193.64, 'duration': 5.76}, {'text': 'de aproximación que haga hacia', 'start': 197.0, 'duration': 4.36}, {'text': 'interpretar el texto que viene a mí que', 'start': 199.4, 'duration': 3.68}, {'text': 'yo transformo en un en un vector o en', 'start': 201.36, 'duration': 3.439}, {'text': 'una estructura de números por eso', 'start': 203.08, 'duration': 3.799}, {'text': 'también es importante tener en cuenta lo', 'start': 204.799, 'duration': 4.121}, {'text': 'que dijimos recién la forma de tocan ia', 'start': 206.879, 'duration': 4.121}, {'text': 'para ver si tomo los elementos o no de', 'start': 208.92, 'duration': 4.599}, {'text': 'manera individual o como parte colectiva', 'start': 211.0, 'duration': 5.239}, {'text': 'o parte de la expresión en cada palabra', 'start': 213.519, 'duration': 5.601}, {'text': 'donde está eh vinculado ese ese carácter', 'start': 216.239, 'duration': 6.121}, {'text': 'especial y justamente la puntuación ver', 'start': 219.12, 'duration': 5.399}, {'text': 'si la voy a tener en consideración o no', 'start': 222.36, 'duration': 4.64}, {'text': 'de acuerdo al sentido que yo busque de', 'start': 224.519, 'duration': 4.321}, {'text': 'el tipo de inteligencia que aplique para', 'start': 227.0, 'duration': 3.92}, {'text': 'la interpretación que haga en algunos', 'start': 228.84, 'duration': 4.2}, {'text': 'casos ustedes ya van a ver más adelante', 'start': 230.92, 'duration': 4.84}, {'text': 'que se puede prescindir de una coma se', 'start': 233.04, 'duration': 5.6}, {'text': 'puede prescindir de un punto o no y en', 'start': 235.76, 'duration': 4.839}, {'text': 'algunos casos el tomar la opción de', 'start': 238.64, 'duration': 5.12}, {'text': 'hacerlo no nos va a hacer peligrar la la', 'start': 240.599, 'duration': 5.28}, {'text': 'eficiencia como decía hace un rato de la', 'start': 243.76, 'duration': 4.88}, {'text': 'interpretación del', 'start': 245.879, 'duration': 2.761}, {'text': 'texto Obviamente que todo esto que', 'start': 248.92, 'duration': 4.319}, {'text': 'estamos hablando no hace otra cosa que', 'start': 251.079, 'duration': 4.72}, {'text': 'como dijimos hace un rato generar', 'start': 253.239, 'duration': 4.641}, {'text': 'información transformada de texto en', 'start': 255.799, 'duration': 4.081}, {'text': 'vectores pero para que la inteligencia', 'start': 257.88, 'duration': 4.079}, {'text': 'empiece a entender el sentido de ese', 'start': 259.88, 'duration': 4.24}, {'text': 'texto y empiece a serer distintos tipos', 'start': 261.959, 'duration': 4.361}, {'text': 'de tarea justamente con textos que', 'start': 264.12, 'duration': 4.639}, {'text': 'empiecen a aparecer como input Por ende', 'start': 266.32, 'duration': 5.52}, {'text': 'este tipo de información representa un', 'start': 268.759, 'duration': 4.88}, {'text': 'conjunto de datos que está a', 'start': 271.84, 'duration': 3.919}, {'text': 'disponibilidad de esa inteligencia para', 'start': 273.639, 'duration': 4.441}, {'text': 'ser entrenado Por ende ese volumen de', 'start': 275.759, 'duration': 4.401}, {'text': 'datos para el aprendizaje obviamente es', 'start': 278.08, 'duration': 4.6}, {'text': 'un factor muy importante y como cuando', 'start': 280.16, 'duration': 4.4}, {'text': 'vimos el resto de las inteligencias que', 'start': 282.68, 'duration': 4.2}, {'text': 'vimos en el curso o antes en el curso de', 'start': 284.56, 'duration': 4.56}, {'text': 'que venimos llevando adelante justamente', 'start': 286.88, 'duration': 4.36}, {'text': 'Cuanto más datos tengamos obviamente más', 'start': 289.12, 'duration': 4.04}, {'text': 'preciso y efectivo va a ser el modelo sí', 'start': 291.24, 'duration': 3.56}, {'text': 'sabemos que siempre hay un límite no', 'start': 293.16, 'duration': 2.84}, {'text': 'quiere decir que siempre tenga que ser', 'start': 294.8, 'duration': 3.52}, {'text': 'el número máximo Pero obviamente Cuanto', 'start': 296.0, 'duration': 4.16}, {'text': 'más tengamos en principio de Debería ser', 'start': 298.32, 'duration': 4.08}, {'text': 'ese algoritmo mucho más eficiente Por', 'start': 300.16, 'duration': 5.44}, {'text': 'ende o por ello Mejor dicho el el éxito', 'start': 302.4, 'duration': 5.12}, {'text': 'de los grandes este las grandes', 'start': 305.6, 'duration': 4.08}, {'text': 'aplicaciones que hay hoy como GP t4 que', 'start': 307.52, 'duration': 4.679}, {'text': 'han sido entrenadas con cantidades', 'start': 309.68, 'duration': 5.0}, {'text': 'enormes de información y de texto y por', 'start': 312.199, 'duration': 5.881}, {'text': 'eso el alto nivel de eferencia que', 'start': 314.68, 'duration': 6.12}, {'text': 'tienen un tema final a tener presente en', 'start': 318.08, 'duration': 4.88}, {'text': 'este proceso asociado a la tokenización', 'start': 320.8, 'duration': 4.239}, {'text': 'es el manejo de las letras minúsculas y', 'start': 322.96, 'duration': 5.0}, {'text': 'mayúsculas en realidad para la máquina', 'start': 325.039, 'duration': 6.28}, {'text': 'un hola donde la H está en mayúscula o', 'start': 327.96, 'duration': 4.959}, {'text': 'la misma palabra donde la H está en', 'start': 331.319, 'duration': 3.761}, {'text': 'minúscula son dos palabras totalmente', 'start': 332.919, 'duration': 3.601}, {'text': 'diferentes yo tenemos que tenerlo en', 'start': 335.08, 'duration': 3.72}, {'text': 'cuenta porque justamente si nosotros', 'start': 336.52, 'duration': 5.2}, {'text': 'ponemos esta o dejamos libre esta', 'start': 338.8, 'duration': 5.519}, {'text': 'diferenciación entre una palabra y otra', 'start': 341.72, 'duration': 4.4}, {'text': 'simplemente por tener la primera letra', 'start': 344.319, 'duration': 4.841}, {'text': 'mayúscula estamos creando un vector con', 'start': 346.12, 'duration': 5.72}, {'text': 'mayor dimensión ustedes imagínense que', 'start': 349.16, 'duration': 5.12}, {'text': 'todas las palabras tengan esta esta', 'start': 351.84, 'duration': 4.96}, {'text': 'situación de dos palabras diferentes por', 'start': 354.28, 'duration': 5.199}, {'text': 'tener la primera letra en mayúscula o no', 'start': 356.8, 'duration': 5.44}, {'text': 'estaría duplicando Prácticamente todo el', 'start': 359.479, 'duration': 4.121}, {'text': 'vocabulario literalmente todo el', 'start': 362.24, 'duration': 2.959}, {'text': 'vocabulario Por lo cual por ejemplo', 'start': 363.6, 'duration': 2.999}, {'text': 'recién el vector que teníamos 18', 'start': 365.199, 'duration': 2.801}, {'text': 'posiciones va a pasar a ser un vector de', 'start': 366.599, 'duration': 3.921}, {'text': '36 posiciones siendo que la palabra es', 'start': 368.0, 'duration': 4.319}, {'text': 'exactamente la misma con lo cual lo que', 'start': 370.52, 'duration': 3.399}, {'text': 'me conviene hacer como proceso de', 'start': 372.319, 'duration': 3.16}, {'text': 'tokenización o parte del proceso de', 'start': 373.919, 'duration': 4.641}, {'text': 'tokenización además de dividirlas con el', 'start': 375.479, 'duration': 4.961}, {'text': 'método split que vimos hace un rato es', 'start': 378.56, 'duration': 3.88}, {'text': 'aplicar lower para poner toda la', 'start': 380.44, 'duration': 4.8}, {'text': 'expresión en minúscula de esa manera mi', 'start': 382.44, 'duration': 5.039}, {'text': 'diccionario va a estar conformado por', 'start': 385.24, 'duration': 4.92}, {'text': 'cuatro palabras de otro modo modo yo', 'start': 387.479, 'duration': 4.361}, {'text': 'tendría que tener un diccionario donde', 'start': 390.16, 'duration': 5.0}, {'text': 'por ejemplo Hola mundo y buenos que', 'start': 391.84, 'duration': 5.759}, {'text': 'tiene la posibilidad de tener una', 'start': 395.16, 'duration': 3.8}, {'text': 'expresión en minúscula y mayúscula', 'start': 397.599, 'duration': 2.561}, {'text': 'tendría que tener contemplados los dos', 'start': 398.96, 'duration': 2.6}, {'text': 'casos con lo cual tenía un diccionario', 'start': 400.16, 'duration': 4.319}, {'text': 'de siete palabras en lugar de cuatro', 'start': 401.56, 'duration': 5.32}, {'text': 'como hay', 'start': 404.479, 'duration': 2.401}, {'text': 'aquí el siguiente concepto importante', 'start': 407.28, 'duration': 5.0}, {'text': 'son las stop words sí o palabras de', 'start': 409.84, 'duration': 4.84}, {'text': 'parada bien tenemos por ejemplo aquí una', 'start': 412.28, 'duration': 4.039}, {'text': 'frase de ejemplo que la he puesto en una', 'start': 414.68, 'duration': 4.359}, {'text': 'var de texto en algunos países los días', 'start': 416.319, 'duration': 5.681}, {'text': 'son muy largos y las noches muy cortas', 'start': 419.039, 'duration': 6.56}, {'text': 'bien si yo toqu eniso esta frase que', 'start': 422.0, 'duration': 8.12}, {'text': 'tiene 13 palabras tendría una toca de 12', 'start': 425.599, 'duration': 6.6}, {'text': 'palabras por qué Porque está la palabra', 'start': 430.12, 'duration': 3.919}, {'text': 'muy que se repite dos veces como vimos', 'start': 432.199, 'duration': 4.12}, {'text': 'recién el diccionario sería de 12', 'start': 434.039, 'duration': 4.321}, {'text': 'palabras a partir de este texto está', 'start': 436.319, 'duration': 5.641}, {'text': 'bien Ahora en esta frase existen lo que', 'start': 438.36, 'duration': 6.44}, {'text': 'se llaman stop Wars sí las spw Por lo', 'start': 441.96, 'duration': 5.76}, {'text': 'general son palabras que forman parte de', 'start': 444.8, 'duration': 6.119}, {'text': 'las frases pero representan algo que no', 'start': 447.72, 'duration': 5.68}, {'text': 'cambia el sentido de la frase y Por ende', 'start': 450.919, 'duration': 4.68}, {'text': 'se puede llegar a prescindir de ellas en', 'start': 453.4, 'duration': 5.479}, {'text': 'este caso por ejemplo las palabras en', 'start': 455.599, 'duration': 8.0}, {'text': 'los las muy e son palabras del lenguaje', 'start': 458.879, 'duration': 6.6}, {'text': 'español que están en todas partes Es', 'start': 463.599, 'duration': 3.401}, {'text': 'decir no va a ser algo que voy a', 'start': 465.479, 'duration': 2.921}, {'text': 'encontrar en esta frase y no voy a', 'start': 467.0, 'duration': 3.159}, {'text': 'encontrar en muchas otras frases porque', 'start': 468.4, 'duration': 3.799}, {'text': 'son justamente elementos clásicos de', 'start': 470.159, 'duration': 4.561}, {'text': 'nuestro lenguaje y Por ende justamente', 'start': 472.199, 'duration': 4.921}, {'text': 'no aportan mucho a la frase ni tampoco', 'start': 474.72, 'duration': 4.72}, {'text': 'cambian mucho el sentido de la frase si', 'start': 477.12, 'duration': 5.079}, {'text': 'esas stop Wars no están en este caso si', 'start': 479.44, 'duration': 5.039}, {'text': 'yo me', 'start': 482.199, 'duration': 2.28}, {'text': 'circunscribieron las work que', 'start': 492.479, 'duration': 5.68}, {'text': 'mencionábamos recién Entonces esto puede', 'start': 495.28, 'duration': 5.28}, {'text': 'verse que a la hora de leerlo desde la', 'start': 498.159, 'duration': 4.361}, {'text': 'que es nuestro conocimiento del lenguaje', 'start': 500.56, 'duration': 4.72}, {'text': 'podía representar una frase que se puede', 'start': 502.52, 'duration': 4.32}, {'text': 'interpretar más o menos Hacia dónde va', 'start': 505.28, 'duration': 4.0}, {'text': 'pero no es muy clara bueno Esto es muy', 'start': 506.84, 'duration': 4.56}, {'text': 'importante en el mundo en LP porque la', 'start': 509.28, 'duration': 4.239}, {'text': 'máquina sí lo va a poder interpretar de', 'start': 511.4, 'duration': 4.4}, {'text': 'manera correcta y lo que estoy haciendo', 'start': 513.519, 'duration': 5.281}, {'text': 'aquí es prescindiendo de una cantidad de', 'start': 515.8, 'duration': 5.84}, {'text': 'dimensiones en este supuesto vector si', 'start': 518.8, 'duration': 5.28}, {'text': 'contemplara las stop Word dentro que', 'start': 521.64, 'duration': 4.92}, {'text': 'justamente al no tenerlos se reduce el', 'start': 524.08, 'duration': 5.28}, {'text': 'vector yo gano como ustedes ya imaginan', 'start': 526.56, 'duration': 5.48}, {'text': 'por supuesto en velocidad en rapidez y', 'start': 529.36, 'duration': 5.52}, {'text': 'en eficiencia justamente teniendo menos', 'start': 532.04, 'duration': 4.52}, {'text': 'dimensiones que teniendo una cantidad de', 'start': 534.88, 'duration': 4.04}, {'text': 'dimensiones mayor y quizás innecesaria a', 'start': 536.56, 'duration': 5.0}, {'text': 'los fines del', 'start': 538.92, 'duration': 2.64}, {'text': 'nlp Bueno pero se terminaron las', 'start': 542.88, 'duration': 4.639}, {'text': 'palabras se terminaron las definiciones', 'start': 545.8, 'duration': 4.2}, {'text': 'y los conceptos es hora de aplicar', 'start': 547.519, 'duration': 5.041}, {'text': 'nuestro primer código de nlp para', 'start': 550.0, 'duration': 4.519}, {'text': 'empezar a trabajar en este caso', 'start': 552.56, 'duration': 4.76}, {'text': 'particular con stop Wars y tokenización', 'start': 554.519, 'duration': 6.161}, {'text': 'para ello tenemos este la pnl 1 que es', 'start': 557.32, 'duration': 5.0}, {'text': 'un archivo de colap que es el primero', 'start': 560.68, 'duration': 3.279}, {'text': 'con el cual vamos a empezar a trabajar y', 'start': 562.32, 'duration': 3.16}, {'text': 'es uno de los archivos que ustedes', 'start': 563.959, 'duration': 4.161}, {'text': 'tienen en el campo virtual vamos hacia', 'start': 565.48, 'duration': 4.919}, {'text': 'ello', 'start': 568.12, 'duration': 3.8}, {'text': 'aquí estamos entonces en el ámbito de', 'start': 570.399, 'duration': 4.401}, {'text': 'Cola con el la pnl 1 bien tenemos la', 'start': 571.92, 'duration': 5.12}, {'text': 'variable texto a la cual le ponemos la', 'start': 574.8, 'duration': 4.24}, {'text': 'misma frase que hablamos hace un rato en', 'start': 577.04, 'duration': 4.08}, {'text': 'algunos países los días son muy largos y', 'start': 579.04, 'duration': 4.08}, {'text': 'las noches muy cortas lo que vamos a', 'start': 581.12, 'duration': 4.44}, {'text': 'hacer como primera medida es importar la', 'start': 583.12, 'duration': 6.92}, {'text': 'librería nltk nltk significa librería', 'start': 585.56, 'duration': 8.2}, {'text': 'natural Language tool kit Entonces', 'start': 590.04, 'duration': 5.32}, {'text': 'tenemos que importar esa librería y', 'start': 593.76, 'duration': 3.12}, {'text': 'tenemos que bajar dos archivos que son', 'start': 595.36, 'duration': 2.8}, {'text': 'importantes el primero para la', 'start': 596.88, 'duration': 3.56}, {'text': 'tokenización y el segundo para trabajar', 'start': 598.16, 'duration': 4.48}, {'text': 'con las stop World Así que vamos', 'start': 600.44, 'duration': 3.6}, {'text': 'entonces con la primer celda que no lo', 'start': 602.64, 'duration': 3.04}, {'text': 'habíamos ejecutado que es poner dentro', 'start': 604.04, 'duration': 5.2}, {'text': 'de texto esa frase y luego importar', 'start': 605.68, 'duration': 5.8}, {'text': 'estas librerías paso seguido que lo', 'start': 609.24, 'duration': 3.64}, {'text': 'ponemos en una celda aparte pero lo', 'start': 611.48, 'duration': 3.68}, {'text': 'podríamos Haber puesto junto con las dos', 'start': 612.88, 'duration': 4.199}, {'text': 'las tres líneas anteriores Perdón', 'start': 615.16, 'duration': 5.56}, {'text': 'tenemos que también incorporar eh d nltk', 'start': 617.079, 'duration': 6.921}, {'text': 'Corpus stop Wars y d nltk tokenize Word', 'start': 620.72, 'duration': 6.2}, {'text': 'tokenize bien importamos esas librerías', 'start': 624.0, 'duration': 5.32}, {'text': 'también y ahora empezamos a ver el tema', 'start': 626.92, 'duration': 4.8}, {'text': 'de las stop Wars en principio voy a', 'start': 629.32, 'duration': 3.759}, {'text': 'crear una variable que le voy a poner', 'start': 631.72, 'duration': 4.559}, {'text': 'stop bajo Wars en la cual voy a volcar', 'start': 633.079, 'duration': 6.241}, {'text': 'todo el dicionario de palabras de stop', 'start': 636.279, 'duration': 5.641}, {'text': 'Wars que existen en el ámbito del', 'start': 639.32, 'duration': 5.079}, {'text': 'Castellano sí palabras que tienen que', 'start': 641.92, 'duration': 4.24}, {'text': 'ver justamente con lo que voy marcando', 'start': 644.399, 'duration': 3.601}, {'text': 'aquí arriba con esta librería stop Wars', 'start': 646.16, 'duration': 4.04}, {'text': 'que pertenece al natural Language', 'start': 648.0, 'duration': 5.32}, {'text': 'toolkit y de hago una impresión para que', 'start': 650.2, 'duration': 6.079}, {'text': 'se vea justamente Cuáles son todas las', 'start': 653.32, 'duration': 6.199}, {'text': 'stop Wars en español así que ejecuto', 'start': 656.279, 'duration': 5.921}, {'text': 'esta instrucción y aquí tengo una lista', 'start': 659.519, 'duration': 6.161}, {'text': 'muy larga que bueno la podrían tirar a', 'start': 662.2, 'duration': 5.84}, {'text': 'una Ray si quisieran podrían convertir', 'start': 665.68, 'duration': 4.32}, {'text': 'esa variable como sabemos hacer de', 'start': 668.04, 'duration': 5.88}, {'text': 'costumbre stws taray para poder verla de', 'start': 670.0, 'duration': 6.24}, {'text': 'una manera más más amigable est una al', 'start': 673.92, 'duration': 3.919}, {'text': 'lado de otra y no una bajo otra pero a', 'start': 676.24, 'duration': 3.56}, {'text': 'los fines prácticos si aquí tenemos', 'start': 677.839, 'duration': 4.56}, {'text': 'entonces todas las palabras que forman', 'start': 679.8, 'duration': 4.839}, {'text': 'parte de las stop words o lo que está', 'start': 682.399, 'duration': 4.401}, {'text': 'definido dentro del natural Language', 'start': 684.639, 'duration': 5.921}, {'text': 'tool kit en español como stop Word', 'start': 686.8, 'duration': 6.52}, {'text': 'obviamente es una lista muy muy larga si', 'start': 690.56, 'duration': 4.36}, {'text': 'como siempre es complicado recorrerla de', 'start': 693.32, 'duration': 3.68}, {'text': 'este modo Pero bueno lo dejo en ustedes', 'start': 694.92, 'duration': 6.039}, {'text': 'Poder recorrerla De punta a punta bien', 'start': 697.0, 'duration': 6.68}, {'text': 'una vez que tenemos esto lo siguiente', 'start': 700.959, 'duration': 6.281}, {'text': 'sería tokenizar la frase texto si la que', 'start': 703.68, 'duration': 6.44}, {'text': 'teníamos arriba de todo que volvemos ha', 'start': 707.24, 'duration': 4.8}, {'text': 'arriba nuevamente en algunos países los', 'start': 710.12, 'duration': 3.839}, {'text': 'días son muy largos y las noches muy', 'start': 712.04, 'duration': 4.799}, {'text': 'cortas bien Voy a', 'start': 713.959, 'duration': 6.12}, {'text': 'tokenizar esa frase de De qué modo con', 'start': 716.839, 'duration': 6.24}, {'text': 'Word tokenize de texto de la variable', 'start': 720.079, 'duration': 6.081}, {'text': 'texto y voy a poner ese resultado dentro', 'start': 723.079, 'duration': 6.0}, {'text': 'de la variable tokens es decir que en', 'start': 726.16, 'duration': 6.56}, {'text': 'tokens van a estar Qué cosa todas las', 'start': 729.079, 'duration': 5.481}, {'text': 'palabras de esa', 'start': 732.72, 'duration': 4.84}, {'text': 'frase luego lo que voy a hacer va a ser', 'start': 734.56, 'duration': 6.44}, {'text': 'recorrer cada una de esas palabras por', 'start': 737.56, 'duration': 7.16}, {'text': 'eso pongo Word Forward in tokens por', 'start': 741.0, 'duration': 6.56}, {'text': 'cada palabra de cada una de las palabras', 'start': 744.72, 'duration': 4.44}, {'text': 'que están en la colección de token se', 'start': 747.56, 'duration': 2.639}, {'text': 'acuérdense que la colección de token', 'start': 749.16, 'duration': 2.52}, {'text': 'fíjense que ahí me paro y me aparece la', 'start': 750.199, 'duration': 3.76}, {'text': 'ayuda está conformada por tres', 'start': 751.68, 'duration': 7.0}, {'text': 'items bien y luego le pongo como', 'start': 753.959, 'duration': 8.24}, {'text': 'condición If not Word la palabra', 'start': 758.68, 'duration': 7.159}, {'text': 'concretamente in stop Wars con esto', 'start': 762.199, 'duration': 6.0}, {'text': 'resumo por cada palabra que está en', 'start': 765.839, 'duration': 7.041}, {'text': 'tokens pero que no está en la hop Word', 'start': 768.199, 'duration': 6.721}, {'text': 'con lo cual me quedo con las palabras', 'start': 772.88, 'duration': 5.319}, {'text': 'que están fuera de las stop Word y luego', 'start': 774.92, 'duration': 5.64}, {'text': 'imprimo el contenido de esta variable', 'start': 778.199, 'duration': 5.121}, {'text': 'que le he puesto texto ssw como siendo', 'start': 780.56, 'duration': 3.76}, {'text': 'bueno', 'start': 783.32, 'duration': 5.24}, {'text': 'stop texto sin stop Wars Perdón entonces', 'start': 784.32, 'duration': 6.8}, {'text': 'ejecuto esto y fíjense lo que me muestra', 'start': 788.56, 'duration': 4.519}, {'text': 'que es lo que habíamos visto hoy en el', 'start': 791.12, 'duration': 5.839}, {'text': 'ejemplo en la parte teórica en países', 'start': 793.079, 'duration': 8.841}, {'text': 'días largos noches cortas pero yo veo', 'start': 796.959, 'duration': 9.56}, {'text': 'aquí si me voy a las stop Wars y subo un', 'start': 801.92, 'duration': 5.84}, {'text': 'poquito', 'start': 806.519, 'duration': 3.12}, {'text': 'aquí', 'start': 807.76, 'duration': 5.879}, {'text': 'rápidamente veo que n está dentro de las', 'start': 809.639, 'duration': 5.32}, {'text': 'stop', 'start': 813.639, 'duration': 4.961}, {'text': 'Wars Qué pasó que me muestra quién', 'start': 814.959, 'duration': 7.0}, {'text': 'siendo que yo le puse como condición que', 'start': 818.6, 'duration': 5.599}, {'text': 'lo que tenía que estar dentro de texto', 'start': 821.959, 'duration': 5.12}, {'text': 'ssb debían ser aquellas palabras que no', 'start': 824.199, 'duration': 5.721}, {'text': 'están dentro de War Bueno lo que pasa es', 'start': 827.079, 'duration': 5.44}, {'text': 'que como ustedes pueden apreciar aquí en', 'start': 829.92, 'duration': 6.279}, {'text': 'está con la e en mayúscula mientras que', 'start': 832.519, 'duration': 8.24}, {'text': 'en las stop Wars volvemos a aquí en está', 'start': 836.199, 'duration': 7.56}, {'text': 'como todas las stop Wars en minúscula', 'start': 840.759, 'duration': 4.64}, {'text': 'entonces lo que tenemos que hacer es', 'start': 843.759, 'duration': 4.2}, {'text': 'reconfigurar lo que hicimos Recién con', 'start': 845.399, 'duration': 4.12}, {'text': 'una instrucción', 'start': 847.959, 'duration': 4.601}, {'text': 'previa texto igual a texto pun l también', 'start': 849.519, 'duration': 4.481}, {'text': 'lo vimos en la teoría esto y también es', 'start': 852.56, 'duration': 3.24}, {'text': 'una instrucción de python un método de', 'start': 854.0, 'duration': 3.279}, {'text': 'python que ya lo conocen bastante con lo', 'start': 855.8, 'duration': 3.56}, {'text': 'cual con esto voy a convertir toda la', 'start': 857.279, 'duration': 4.841}, {'text': 'frase De punta a punta en minúscula y', 'start': 859.36, 'duration': 4.839}, {'text': 'voy a volver a ejecutar las mismas tres', 'start': 862.12, 'duration': 4.159}, {'text': 'líneas que ejecutamos antes y voy a ver', 'start': 864.199, 'duration': 4.681}, {'text': 'que ahora van a aparecer la misma toen', 'start': 866.279, 'duration': 4.881}, {'text': 'ación es decir la misma eh el mismo', 'start': 868.88, 'duration': 4.6}, {'text': 'arreglo el mismo aray que tiene aquellas', 'start': 871.16, 'duration': 4.08}, {'text': 'palabras tokenizadas pero que no están', 'start': 873.48, 'duration': 4.479}, {'text': 'en el Word en este caso sin la palabra', 'start': 875.24, 'duration': 5.88}, {'text': 'en que había salido antes bien con esto', 'start': 877.959, 'duration': 5.641}, {'text': 'Terminamos el primer lab de este', 'start': 881.12, 'duration': 4.88}, {'text': '[Música]', 'start': 883.6, 'duration': 4.72}, {'text': 'curso los conceptos que tenemos que ver', 'start': 886.0, 'duration': 5.199}, {'text': 'a continuación son estos dos stemin y', 'start': 888.32, 'duration': 4.72}, {'text': 'lematización en realidad tienen', 'start': 891.199, 'duration': 3.401}, {'text': 'propósitos similares pero tienen', 'start': 893.04, 'duration': 3.96}, {'text': 'técnicas diferentes de qué se trata esto', 'start': 894.6, 'duration': 4.08}, {'text': 'en realidad vamos a tener en cuenta al', 'start': 897.0, 'duration': 3.36}, {'text': 'algunas cuestiones antes de entrar en', 'start': 898.68, 'duration': 4.12}, {'text': 'las características de cada uno de ellos', 'start': 900.36, 'duration': 5.279}, {'text': 'las palabras similares se tratan como', 'start': 902.8, 'duration': 6.08}, {'text': 'entidades separadas es decir corre', 'start': 905.639, 'duration': 6.56}, {'text': 'corriendo o corre son palabras muy', 'start': 908.88, 'duration': 5.6}, {'text': 'similares pero habitualmente se tratan', 'start': 912.199, 'duration': 4.241}, {'text': 'por ser palabras distintas con entidades', 'start': 914.48, 'duration': 5.039}, {'text': 'separadas las mismas en realidad van a', 'start': 916.44, 'duration': 4.72}, {'text': 'ser representadas por vectores que van a', 'start': 919.519, 'duration': 4.0}, {'text': 'estar muy cerca a unos de otros por qué', 'start': 921.16, 'duration': 4.0}, {'text': 'porque las tres palabras tienen un', 'start': 923.519, 'duration': 3.801}, {'text': 'sentido similar o un sentido que', 'start': 925.16, 'duration': 4.799}, {'text': 'asociativamente es parecido pero van a', 'start': 927.32, 'duration': 4.16}, {'text': 'estar representadas por vectores', 'start': 929.959, 'duration': 3.68}, {'text': 'diferentes esto lo teníamos en la imagen', 'start': 931.48, 'duration': 4.12}, {'text': 'que vimos hace un rato vamos a ver un', 'start': 933.639, 'duration': 4.401}, {'text': 'poco ella para poder recuperar este', 'start': 935.6, 'duration': 4.599}, {'text': 'concepto que está aquí recuerdan este', 'start': 938.04, 'duration': 4.64}, {'text': 'gráfico bueno supongamos que esto de', 'start': 940.199, 'duration': 5.521}, {'text': 'correr corriendo corre fueran estos', 'start': 942.68, 'duration': 5.599}, {'text': 'vectores que probablemente justamente', 'start': 945.72, 'duration': 4.599}, {'text': 'como son palabras que tienen un sentido', 'start': 948.279, 'duration': 6.36}, {'text': 'muy similar estén cerca estos vectores', 'start': 950.319, 'duration': 6.08}, {'text': 'eso va a ser justamente una', 'start': 954.639, 'duration': 4.64}, {'text': 'representación vectorial que representa', 'start': 956.399, 'duration': 5.12}, {'text': 'esa realidad de palabras similares pero', 'start': 959.279, 'duration': 5.281}, {'text': 'concretamente yo voy a estar teniendo un', 'start': 961.519, 'duration': 6.521}, {'text': 'espacio con tres dimensiones Y eso es lo', 'start': 964.56, 'duration': 6.199}, {'text': 'que trato de evitar con el steaming y la', 'start': 968.04, 'duration': 5.68}, {'text': 'lematización por eso como dice aquí lo', 'start': 970.759, 'duration': 5.08}, {'text': 'que vimos recién genera una gran', 'start': 973.72, 'duration': 4.479}, {'text': 'dimensionalidad la cual se podría', 'start': 975.839, 'duration': 5.201}, {'text': 'reducir si utilizáramos una misma raíz', 'start': 978.199, 'duration': 5.32}, {'text': 'de esas palabras para representarlas', 'start': 981.04, 'duration': 5.279}, {'text': 'todas del mismo modo es decir correr', 'start': 983.519, 'duration': 5.8}, {'text': 'corriendo y corre tienen una palabra', 'start': 986.319, 'duration': 5.52}, {'text': 'raíz que puede ser asociada a las tres y', 'start': 989.319, 'duration': 4.801}, {'text': 'de esa manera representar las tres con', 'start': 991.839, 'duration': 4.44}, {'text': 'una palabra que sea representativa y no', 'start': 994.12, 'duration': 4.519}, {'text': 'con las tres por separada para eso', 'start': 996.279, 'duration': 4.641}, {'text': 'existen dos técnicas que son stemin y', 'start': 998.639, 'duration': 4.44}, {'text': 'lematización y vamos a ver justamente', 'start': 1000.92, 'duration': 4.52}, {'text': 'cada una de ellas de qué se', 'start': 1003.079, 'duration': 5.32}, {'text': 'trata el stemin es una técnica que', 'start': 1005.44, 'duration': 5.319}, {'text': 'elimina los sufijos de una palabra por', 'start': 1008.399, 'duration': 5.721}, {'text': 'ejemplo tengo caminar y caminando ambas', 'start': 1010.759, 'duration': 6.08}, {'text': 'palabras se van a transformar en camín', 'start': 1014.12, 'duration': 5.44}, {'text': 'es decir toma lo que tienen en común', 'start': 1016.839, 'duration': 5.081}, {'text': 'ambas palabras y a la primera le quita', 'start': 1019.56, 'duration': 6.04}, {'text': 'el ar y a la segunda le quita el and con', 'start': 1021.92, 'duration': 6.919}, {'text': 'lo cual de dos palabras paso a tener una', 'start': 1025.6, 'duration': 6.12}, {'text': 'de dos dimensiones paso a una la', 'start': 1028.839, 'duration': 5.6}, {'text': 'lematización busca un objetivo similar', 'start': 1031.72, 'duration': 4.959}, {'text': 'pero con una una técnica o una modalidad', 'start': 1034.439, 'duration': 4.6}, {'text': 'diferente la lematización lo que hace es', 'start': 1036.679, 'duration': 6.721}, {'text': 'Buscar la palabra raíz u origen de esas', 'start': 1039.039, 'duration': 6.361}, {'text': 'palabras que tienen un sentido similar', 'start': 1043.4, 'duration': 5.96}, {'text': 'por ejemplo caminar caminando Caminaré', 'start': 1045.4, 'duration': 6.84}, {'text': 'camino se transforman en que su palabra', 'start': 1049.36, 'duration': 6.6}, {'text': 'raíz es caminar aquí no quita una parte', 'start': 1052.24, 'duration': 6.559}, {'text': 'de la palabra para llegar a lo que sería', 'start': 1055.96, 'duration': 4.8}, {'text': 'una palabra resumida quitando lo que', 'start': 1058.799, 'duration': 3.681}, {'text': 'decíamos recién los sufijos como hace el', 'start': 1060.76, 'duration': 5.4}, {'text': 'steaming sino que busca la palabra raíz', 'start': 1062.48, 'duration': 6.04}, {'text': 'de esas cuatro palabras esto obviamente', 'start': 1066.16, 'duration': 4.72}, {'text': 'es un proceso que es más lento porque lo', 'start': 1068.52, 'duration': 4.76}, {'text': 'que hace el St Es simplemente recortar', 'start': 1070.88, 'duration': 4.159}, {'text': 'parte de una palabra aquí lo que tiene', 'start': 1073.28, 'duration': 3.519}, {'text': 'que hacer es tomar todas esas palabras', 'start': 1075.039, 'duration': 3.081}, {'text': 'tod Ese Conjunto de palabras en este', 'start': 1076.799, 'duration': 4.12}, {'text': 'caso de cuatro y buscar cuál es la', 'start': 1078.12, 'duration': 4.76}, {'text': 'palabra raíz que representa esas cuatro', 'start': 1080.919, 'duration': 4.0}, {'text': 'Pero nuevamente el objetivo es el mismo', 'start': 1082.88, 'duration': 4.36}, {'text': 'porque paso de tener en este caso cuatro', 'start': 1084.919, 'duration': 5.111}, {'text': 'dimensiones a solamente una', 'start': 1087.24, 'duration': 3.88}, {'text': '[Música]', 'start': 1090.03, 'duration': 4.33}, {'text': 'dimensión al igual que hace un rato esto', 'start': 1091.12, 'duration': 5.0}, {'text': 'lo vamos a ver en la práctica por eso', 'start': 1094.36, 'duration': 3.96}, {'text': 'existe otro archivo de colab que tienen', 'start': 1096.12, 'duration': 4.28}, {'text': 'en el campus virtual que se llama lab', 'start': 1098.32, 'duration': 5.12}, {'text': 'pnl 2 y justamente me da un ejemplo de', 'start': 1100.4, 'duration': 6.36}, {'text': 'streaming y de lematización vamos hacia', 'start': 1103.44, 'duration': 5.68}, {'text': 'ello bien est vamos ahora nuevamente en', 'start': 1106.76, 'duration': 5.48}, {'text': 'colap pero ahora en el la pnl 2 en este', 'start': 1109.12, 'duration': 4.76}, {'text': 'caso el tema es stemin como decíamos', 'start': 1112.24, 'duration': 3.16}, {'text': 'recién y lo primero que vamos a hacer es', 'start': 1113.88, 'duration': 4.4}, {'text': 'importar bueno natural Language toolkit', 'start': 1115.4, 'duration': 5.56}, {'text': 'y vamos a hacer un Download parecido a', 'start': 1118.28, 'duration': 4.24}, {'text': 'lo que hicimos En el lab anterior pero', 'start': 1120.96, 'duration': 2.959}, {'text': 'ahora de', 'start': 1122.52, 'duration': 4.48}, {'text': 'wordnet Por qué wordnet cuando Antes', 'start': 1123.919, 'duration': 7.0}, {'text': 'había elegido Punk y stop Wars bueno en', 'start': 1127.0, 'duration': 6.36}, {'text': 'el caso de punkt tenía que ver con la', 'start': 1130.919, 'duration': 4.681}, {'text': 'tokenización y en el caso que nos', 'start': 1133.36, 'duration': 4.92}, {'text': 'ocupaba en el primer lab yo quería sola', 'start': 1135.6, 'duration': 5.92}, {'text': 'ente poder tokenizar esta frase es decir', 'start': 1138.28, 'duration': 5.04}, {'text': 'Tomar las palabras separadas de esta', 'start': 1141.52, 'duration': 4.12}, {'text': 'frase y las stopwords eran con el', 'start': 1143.32, 'duration': 3.76}, {'text': 'propósito que dimos recién que tenía que', 'start': 1145.64, 'duration': 3.56}, {'text': 'ver con la posibilidad de quitar de esa', 'start': 1147.08, 'duration': 5.719}, {'text': 'frase las stws en este caso la el', 'start': 1149.2, 'duration': 5.68}, {'text': 'stemming y la lematización se trata de', 'start': 1152.799, 'duration': 5.721}, {'text': 'poder inducir a que la inteligencia me', 'start': 1154.88, 'duration': 5.72}, {'text': 'permita en algunos casos quitar el', 'start': 1158.52, 'duration': 4.36}, {'text': 'sufijo y en otros casos encontrar la', 'start': 1160.6, 'duration': 4.28}, {'text': 'palabra raíz y para eso necesita como', 'start': 1162.88, 'duration': 5.56}, {'text': 'referencia una librería que contenga el', 'start': 1164.88, 'duration': 5.44}, {'text': 'vocabulario luego el vocabulario yo lo', 'start': 1168.44, 'duration': 4.239}, {'text': 'puedo configurar para que esté en un', 'start': 1170.32, 'duration': 4.16}, {'text': 'determinado idioma Pero por eso en este', 'start': 1172.679, 'duration': 4.12}, {'text': 'caso particular que se diferencia', 'start': 1174.48, 'duration': 3.8}, {'text': 'claramente de los propósitos del lab', 'start': 1176.799, 'duration': 3.12}, {'text': 'anterior tengo que carrar la librería', 'start': 1178.28, 'duration': 3.8}, {'text': 'wordnet Así que lo primero que hago es', 'start': 1179.919, 'duration': 5.24}, {'text': 'eso y una vez terminado esto lo que voy', 'start': 1182.08, 'duration': 8.44}, {'text': 'a llamar d nltk stem importar snowball', 'start': 1185.159, 'duration': 8.76}, {'text': 'steamer esta librería con la cual voy a', 'start': 1190.52, 'duration': 6.159}, {'text': 'crear una instancia una variable que le', 'start': 1193.919, 'duration': 5.24}, {'text': 'voy a poner steamer instancia a través', 'start': 1196.679, 'duration': 5.281}, {'text': 'justamente snowball steamer configurando', 'start': 1199.159, 'duration': 6.161}, {'text': 'esa instancia de snowball es decir', 'start': 1201.96, 'duration': 5.599}, {'text': 'básicamente lo que va a representar la', 'start': 1205.32, 'duration': 5.16}, {'text': 'acción del steamer en español con lo', 'start': 1207.559, 'duration': 4.961}, {'text': 'cual creo esta variable Y a partir de', 'start': 1210.48, 'duration': 3.559}, {'text': 'eso y justamente con esta variable de', 'start': 1212.52, 'duration': 4.24}, {'text': 'objeto lo que voy a hacer va a ser tomar', 'start': 1214.039, 'duration': 4.361}, {'text': 'tres palabras como las que tomamos', 'start': 1216.76, 'duration': 4.24}, {'text': 'recién como ejemplo y ver el steamer', 'start': 1218.4, 'duration': 4.96}, {'text': 'Cuál es la reducción que hace al quitar', 'start': 1221.0, 'duration': 4.24}, {'text': 'los sufijos de cada una de esas palabras', 'start': 1223.36, 'duration': 4.0}, {'text': 'por eso hago tres prints Cuando pruebo', 'start': 1225.24, 'duration': 5.96}, {'text': 'esto veo que comiendo comer y comió en', 'start': 1227.36, 'duration': 6.04}, {'text': 'los tres casos el steaming lo que hizo', 'start': 1231.2, 'duration': 5.08}, {'text': 'fue quitarle los sufijos y reducirlos a', 'start': 1233.4, 'duration': 4.8}, {'text': 'las palabras que tienen en común la c la', 'start': 1236.28, 'duration': 3.639}, {'text': 'o y la', 'start': 1238.2, 'duration': 4.08}, {'text': 'm bien es el turno ahora de la', 'start': 1239.919, 'duration': 4.401}, {'text': 'lematización en el caso de la', 'start': 1242.28, 'duration': 4.08}, {'text': 'lematización no vamos a usar la librería', 'start': 1244.32, 'duration': 5.0}, {'text': 'nltk que usamos antes para el steaming y', 'start': 1246.36, 'duration': 5.12}, {'text': 'que también usamos en el lav anterior', 'start': 1249.32, 'duration': 4.56}, {'text': 'dado que si bien tiene la herramienta', 'start': 1251.48, 'duration': 3.96}, {'text': 'para hacer la lematización esa', 'start': 1253.88, 'duration': 3.24}, {'text': 'herramienta no está disponible en lengua', 'start': 1255.44, 'duration': 4.44}, {'text': 'castellana por eso vamos a recurrir a la', 'start': 1257.12, 'duration': 5.96}, {'text': 'librería spacy que sí tiene esa opción', 'start': 1259.88, 'duration': 5.64}, {'text': 'de lematización en lengua castellana y', 'start': 1263.08, 'duration': 4.479}, {'text': 'de paso me sirve esto para decirles de', 'start': 1265.52, 'duration': 4.039}, {'text': 'que estamos sumando una librería más', 'start': 1267.559, 'duration': 4.36}, {'text': 'para ese tipo de actividades u otras y', 'start': 1269.559, 'duration': 4.961}, {'text': 'que eso no implica que sean las dos', 'start': 1271.919, 'duration': 4.281}, {'text': 'únicas que existen para este tipo de', 'start': 1274.52, 'duration': 4.279}, {'text': 'tareas en el mundo del nlp pero sí es', 'start': 1276.2, 'duration': 4.44}, {'text': 'importante que tengan presente que son', 'start': 1278.799, 'duration': 4.801}, {'text': 'las dos o dos de las más conocidas el', 'start': 1280.64, 'duration': 5.8}, {'text': 'spacy no viene naturalmente instalado en', 'start': 1283.6, 'duration': 5.48}, {'text': 'python como el nl tk por lo tanto', 'start': 1286.44, 'duration': 5.08}, {'text': 'tenemos que instalarlo para eso usamos', 'start': 1289.08, 'duration': 4.76}, {'text': 'el argumento que ya conocemos el método', 'start': 1291.52, 'duration': 3.96}, {'text': 'que ya conocemos la herramienta de', 'start': 1293.84, 'duration': 5.28}, {'text': 'python que es pip pip install spacy y el', 'start': 1295.48, 'duration': 6.12}, {'text': 'menq básicamente es para que no muestre', 'start': 1299.12, 'duration': 3.84}, {'text': 'una serie de información que tiene que', 'start': 1301.6, 'duration': 3.64}, {'text': 'ver con la instalación y luego lo que', 'start': 1302.96, 'duration': 5.44}, {'text': 'tengo que instalar es el diccionario o', 'start': 1305.24, 'duration': 5.96}, {'text': 'el conjunto de palabras justamente que', 'start': 1308.4, 'duration': 5.6}, {'text': 'viene para usar el spacy en castellano', 'start': 1311.2, 'duration': 4.959}, {'text': 'con esta frase que está aquí Bueno esto', 'start': 1314.0, 'duration': 3.64}, {'text': 'tarda mucho yo lo tengo instalado para', 'start': 1316.159, 'duration': 3.281}, {'text': 'no per tiempo lo vamos a considerar como', 'start': 1317.64, 'duration': 4.24}, {'text': 'que ya está pero esto es simplemente', 'start': 1319.44, 'duration': 5.119}, {'text': 'hacerle clic al al Play de cada de cada', 'start': 1321.88, 'duration': 4.799}, {'text': 'una de estas celdas y está instalado por', 'start': 1324.559, 'duration': 3.561}, {'text': 'un lado del spacey y por el otro lado', 'start': 1326.679, 'duration': 3.641}, {'text': 'del dicionario bien Vamos al código', 'start': 1328.12, 'duration': 4.0}, {'text': 'concretamente y lo primero que hago es', 'start': 1330.32, 'duration': 4.839}, {'text': 'importar spacey luego lo que voy a hacer', 'start': 1332.12, 'duration': 5.439}, {'text': 'a continuación va a ser Perdón me qu un', 'start': 1335.159, 'duration': 4.561}, {'text': 'error aquí volvemos a la línea lo que', 'start': 1337.559, 'duration': 5.921}, {'text': 'vamos a hacer a continuación es lobar de', 'start': 1339.72, 'duration': 6.8}, {'text': 'spacy es decir cargar el dicionario de', 'start': 1343.48, 'duration': 5.88}, {'text': 'Castellano y lo voy a cargar dentro de', 'start': 1346.52, 'duration': 5.639}, {'text': 'una variable que se le voy a poner nlp', 'start': 1349.36, 'duration': 5.08}, {'text': 'la cual obviamente va a contener todo', 'start': 1352.159, 'duration': 4.4}, {'text': 'este conjunto de palabras que me ofrece', 'start': 1354.44, 'duration': 6.2}, {'text': 'spacy para la lematización en castellano', 'start': 1356.559, 'duration': 6.24}, {'text': 'paso Seguido lo que voy a hacer es usar', 'start': 1360.64, 'duration': 4.76}, {'text': 'justamente esa variable nlp para hacer', 'start': 1362.799, 'duration': 4.921}, {'text': 'una tokenización de una frase una frase', 'start': 1365.4, 'duration': 4.24}, {'text': 'que en realidad es un poco ficticia pero', 'start': 1367.72, 'duration': 4.4}, {'text': 'tiene que ver con rápidamente demostrar', 'start': 1369.64, 'duration': 4.76}, {'text': 'de qué se trata la lematización y Cómo', 'start': 1372.12, 'duration': 3.6}, {'text': 'podemos visualizar los resultados de', 'start': 1374.4, 'duration': 3.8}, {'text': 'ella Por ende esa frase dice comiendo', 'start': 1375.72, 'duration': 4.28}, {'text': 'comer comió evidentemente no tiene un', 'start': 1378.2, 'duration': 3.599}, {'text': 'sentido en la lengua castellana Pero', 'start': 1380.0, 'duration': 3.52}, {'text': 'insisto a los fines de esta mini', 'start': 1381.799, 'duration': 3.88}, {'text': 'práctica viene bien con lo cual en', 'start': 1383.52, 'duration': 5.68}, {'text': 'tokens gracias a nlp lo que voy a tener', 'start': 1385.679, 'duration': 5.921}, {'text': 'justamente es esta frase separada entre', 'start': 1389.2, 'duration': 5.04}, {'text': 'tokens comiendo comer y comendo y Por', 'start': 1391.6, 'duration': 5.6}, {'text': 'ende con este for voy a recorrer for', 'start': 1394.24, 'duration': 5.4}, {'text': 'token in tokens es decir por cada uno de', 'start': 1397.2, 'duration': 3.68}, {'text': 'esos elementos que están dentro de', 'start': 1399.64, 'duration': 2.96}, {'text': 'tokens por cada uno lo que voy a hacer', 'start': 1400.88, 'duration': 3.84}, {'text': 'es arme un String digamos para que se', 'start': 1402.6, 'duration': 3.4}, {'text': 'vea por pantalla', 'start': 1404.72, 'duration': 4.76}, {'text': 'claramente texto dos puntos token pun', 'start': 1406.0, 'duration': 5.32}, {'text': 'text es decir el token ese mismo', 'start': 1409.48, 'duration': 3.88}, {'text': 'comiendo por ejemplo en el caso y luego', 'start': 1411.32, 'duration': 5.599}, {'text': 'lema Qué sería Cuál es la lematización o', 'start': 1413.36, 'duration': 5.88}, {'text': 'cuál es la palabra resultante de aplicar', 'start': 1416.919, 'duration': 5.401}, {'text': 'la lematización sobre comiendo luego', 'start': 1419.24, 'duration': 5.439}, {'text': 'sobre comer y luego sobrecomo acuérdense', 'start': 1422.32, 'duration': 4.76}, {'text': 'que la lización no quita el sufijo como', 'start': 1424.679, 'duration': 4.36}, {'text': 'el steaming sino que busca una palabra', 'start': 1427.08, 'duration': 4.68}, {'text': 'raíz por eso cuando ejecuto esto me', 'start': 1429.039, 'duration': 5.481}, {'text': 'muestra que para comiendo para comer y', 'start': 1431.76, 'duration': 5.6}, {'text': 'para comió existe una palabra raíz única', 'start': 1434.52, 'duration': 4.56}, {'text': 'que seama se llama comer con lo cual', 'start': 1437.36, 'duration': 3.72}, {'text': 'estoy reduciendo esta posible', 'start': 1439.08, 'duration': 3.719}, {'text': 'dimensionalidad de vectores de tres', 'start': 1441.08, 'duration': 4.64}, {'text': 'palabras a una', 'start': 1442.799, 'duration': 2.921}, {'text': 'sola algunas cuestiones que hay que', 'start': 1446.0, 'duration': 4.24}, {'text': 'tener en cuenta con la lematización que', 'start': 1448.159, 'duration': 3.921}, {'text': 'recién referenciamos Es que la', 'start': 1450.24, 'duration': 4.28}, {'text': 'lematización puede ser más efectiva que', 'start': 1452.08, 'duration': 5.839}, {'text': 'el stemin pero su gasto computacional es', 'start': 1454.52, 'duration': 5.92}, {'text': 'mucho mayor por qué Porque el uso de la', 'start': 1457.919, 'duration': 4.481}, {'text': 'lematización requiere de una etiquetado', 'start': 1460.44, 'duration': 4.239}, {'text': 'previo ya que hay que encontrar una', 'start': 1462.4, 'duration': 4.639}, {'text': 'palabra que represente a un grupo tal', 'start': 1464.679, 'duration': 4.561}, {'text': 'cual veíamos en el ejemplo de reciente', 'start': 1467.039, 'duration': 4.561}, {'text': 'Por ende hay que hacer un trabajo extra', 'start': 1469.24, 'duration': 3.84}, {'text': 'que no existe en el estamiento', 'start': 1471.6, 'duration': 4.28}, {'text': 'simplemente recorto la palabra si veo', 'start': 1473.08, 'duration': 5.44}, {'text': 'aquí estos ejemplos donde este cuadro', 'start': 1475.88, 'duration': 4.519}, {'text': 'que está a la izquierda representa una', 'start': 1478.52, 'duration': 4.879}, {'text': 'lematización comiendo comer y comó se', 'start': 1480.399, 'duration': 6.28}, {'text': 'sintetizan en una palabra comer que es', 'start': 1483.399, 'duration': 5.961}, {'text': 'una etiqueta con la cual está', 'start': 1486.679, 'duration': 5.48}, {'text': 'etiquetando estas tres palabras comiendo', 'start': 1489.36, 'duration': 5.36}, {'text': 'comer y comió con una etiqueta comer en', 'start': 1492.159, 'duration': 4.52}, {'text': 'los tres casos por el contrario en el', 'start': 1494.72, 'duration': 4.28}, {'text': 'caso del stemin con este ejemplo que', 'start': 1496.679, 'duration': 4.88}, {'text': 'está aquí yo lo que estoy haciendo es', 'start': 1499.0, 'duration': 5.72}, {'text': 'simplemente sacar el sufijo es decir', 'start': 1501.559, 'duration': 7.081}, {'text': 'comiendo comer y comió tienen en común', 'start': 1504.72, 'duration': 6.36}, {'text': 'las tres primeras letras con lo cual', 'start': 1508.64, 'duration': 4.6}, {'text': 'aquí el gasto computacional al no tener', 'start': 1511.08, 'duration': 4.16}, {'text': 'que buscar esta palabra raíz como el', 'start': 1513.24, 'duration': 4.08}, {'text': 'caso de comer y etiquetar cada una de', 'start': 1515.24, 'duration': 4.559}, {'text': 'esas palabras con esa etiqueta es', 'start': 1517.32, 'duration': 5.28}, {'text': 'obviamente en el caso del stem mucho', 'start': 1519.799, 'duration': 5.441}, {'text': 'menor el gasto computacional y Por ende', 'start': 1522.6, 'duration': 7.079}, {'text': 'el algoritmo es más rápido', 'start': 1525.24, 'duration': 4.439}, {'text': 'para cerrar el tema St y lematización', 'start': 1530.08, 'duration': 4.199}, {'text': 'vamos a poner foco sobre algunas', 'start': 1532.08, 'duration': 4.04}, {'text': 'aplicaciones en donde se pueden aplicar', 'start': 1534.279, 'duration': 5.88}, {'text': 'valga la redundancia estas dos', 'start': 1536.12, 'duration': 4.039}, {'text': 'técnicas en principio hay empresas que', 'start': 1540.559, 'duration': 5.12}, {'text': 'usan asistentes virtuales o chatbox por', 'start': 1543.0, 'duration': 5.399}, {'text': 'ejemplo Amazon con Alexa o empresas que', 'start': 1545.679, 'duration': 4.961}, {'text': 'proporcionan servicios al cliente que', 'start': 1548.399, 'duration': 4.241}, {'text': 'utilizan la lematización y el stemming', 'start': 1550.64, 'duration': 3.56}, {'text': 'para comprender las consultas de los', 'start': 1552.64, 'duration': 4.039}, {'text': 'usuarios con mayor precisión a ver por', 'start': 1554.2, 'duration': 4.24}, {'text': 'ejemplo si un usuario pregunta al', 'start': 1556.679, 'duration': 3.801}, {'text': 'chatbox de una empresa que tenga', 'start': 1558.44, 'duration': 3.68}, {'text': 'atención al cliente Dónde está su', 'start': 1560.48, 'duration': 4.4}, {'text': 'paquete el chatbox Debería ser capaz de', 'start': 1562.12, 'duration': 5.159}, {'text': 'entender la pregunta así como también', 'start': 1564.88, 'duration': 5.44}, {'text': 'otra pregunta parecida a esa en el', 'start': 1567.279, 'duration': 5.081}, {'text': 'análisis de sentimiento por ejemplo si', 'start': 1570.32, 'duration': 4.04}, {'text': 'vamos a monitorear Twitter con las redes', 'start': 1572.36, 'duration': 3.799}, {'text': 'sociales y alguien twitea por ejemplo', 'start': 1574.36, 'duration': 4.96}, {'text': 'estoy enfadado con la empresa Nno o XX', 'start': 1576.159, 'duration': 4.921}, {'text': 'se podría entender que enfadado y', 'start': 1579.32, 'duration': 4.76}, {'text': 'enojado o irritado son sentimientos', 'start': 1581.08, 'duration': 4.959}, {'text': 'similares y por lo tanto deben ser', 'start': 1584.08, 'duration': 3.64}, {'text': 'tratados de la misma manera para', 'start': 1586.039, 'duration': 4.52}, {'text': 'análisis entonces una lematización en', 'start': 1587.72, 'duration': 5.24}, {'text': 'este caso podría ser que cada vez que', 'start': 1590.559, 'duration': 5.401}, {'text': 'diga enfadado enojado o irritado todas', 'start': 1592.96, 'duration': 5.839}, {'text': 'tengan la misma base raíz que sería un', 'start': 1595.96, 'duration': 4.959}, {'text': 'sentimiento de enojo también con los', 'start': 1598.799, 'duration': 4.441}, {'text': 'motores de búsqueda Ocurre algo parecido', 'start': 1600.919, 'duration': 4.12}, {'text': 'a lo que decíamos en el caso de los', 'start': 1603.24, 'duration': 4.76}, {'text': 'chatbox dado que una consulta expresada', 'start': 1605.039, 'duration': 5.481}, {'text': 'de varias formas diferentes debe dar el', 'start': 1608.0, 'duration': 4.12}, {'text': 'mismo resultado de la búsqueda', 'start': 1610.52, 'duration': 3.48}, {'text': 'zapatillas para correr en la montaña', 'start': 1612.12, 'duration': 3.799}, {'text': 'zapatillas de treking zapatillas de en', 'start': 1614.0, 'duration': 4.919}, {'text': 'senderismo etcétera', 'start': 1615.919, 'duration': 4.721}, {'text': 'otro caso son las empresas que tienen', 'start': 1618.919, 'duration': 3.561}, {'text': 'sistema de recomendación Como por', 'start': 1620.64, 'duration': 5.159}, {'text': 'ejemplo Netflix Spotify Amazon u otras', 'start': 1622.48, 'duration': 6.12}, {'text': 'en donde utilizan la lematización y el', 'start': 1625.799, 'duration': 5.12}, {'text': 'stemming para mejorar la precisión de la', 'start': 1628.6, 'duration': 4.72}, {'text': 'recomendación a ver por ejemplo si un', 'start': 1630.919, 'duration': 4.64}, {'text': 'usuario Busca películas de acción', 'start': 1633.32, 'duration': 4.239}, {'text': 'debería Netflix ser capaz de entregar', 'start': 1635.559, 'duration': 4.48}, {'text': 'películas de guerra o policiales es', 'start': 1637.559, 'duration': 4.72}, {'text': 'decir que tengan que ver con películas', 'start': 1640.039, 'duration': 4.52}, {'text': 'de acción finalmente también se usa', 'start': 1642.279, 'duration': 4.201}, {'text': 'mucho en la publicidad online por', 'start': 1644.559, 'duration': 3.881}, {'text': 'ejemplo para hacer etiquetado en redes', 'start': 1646.48, 'duration': 4.48}, {'text': 'sociales a ver si queremos hacer una', 'start': 1648.44, 'duration': 4.32}, {'text': 'publicidad y queremos vender celulares', 'start': 1650.96, 'duration': 4.28}, {'text': 'por ejemplo o algún accesorio para gente', 'start': 1652.76, 'duration': 4.2}, {'text': 'que le gusta esa tecnología o convive', 'start': 1655.24, 'duration': 3.88}, {'text': 'con esa tecnología es posible que esta', 'start': 1656.96, 'duration': 4.439}, {'text': 'empresa me ponga anuncios no solo con la', 'start': 1659.12, 'duration': 4.679}, {'text': 'palabra celulares sino también con un', 'start': 1661.399, 'duration': 5.481}, {'text': 'disminutivo popular como celus o una', 'start': 1663.799, 'duration': 5.641}, {'text': 'denominación más formal como smartphones', 'start': 1666.88, 'duration': 4.88}, {'text': 'o cualquier denominación con palabras', 'start': 1669.44, 'duration': 4.839}, {'text': 'similares que básicamente representen lo', 'start': 1671.76, 'duration': 4.88}, {'text': 'mismo Hemos llegado al final de esta', 'start': 1674.279, 'duration': 4.041}, {'text': 'clase', 'start': 1676.64, 'duration': 4.879}, {'text': 'nos vemos en la próxima', 'start': 1678.32, 'duration': 3.199}, {'text': '[Música]', 'start': 1681.62, 'duration': 3.23}, {'text': 'clase', 'start': 1685.399, 'duration': 3.0}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#transcripcion=transcript\n",
        "transcripcion=contenido_json\n",
        "# busca el minuto de inicio de la palabra clave o lo que quiero ver\n",
        "def encontrar_minuto_inicio(texto_buscado, transcripcion):\n",
        "    for item in transcripcion:\n",
        "        if texto_buscado in item['text']:\n",
        "            return item['start'] / 60  # Convertir segundos a minutos\n",
        "    return None\n",
        "# Texto que deseas buscar\n",
        "texto_buscado = \"disminutivo popular como\"\n",
        "# Encontrar el minuto de inicio del texto buscado\n",
        "minuto_inicio = encontrar_minuto_inicio(texto_buscado, transcripcion)\n",
        "if minuto_inicio is not None:\n",
        "    print(f\"El texto '{texto_buscado}' comienza en el minuto {minuto_inicio:.2f}\")\n",
        "else:\n",
        "    print(f\"No se encontró el texto '{texto_buscado}' en la transcripción\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPmwuejSWvc_",
        "outputId": "6c14bdc8-dd33-45ed-8134-b0bd20037be5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El texto 'disminutivo popular como' comienza en el minuto 27.73\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transcripcion"
      ],
      "metadata": {
        "id": "DFFgwItSXxOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Esta funcion busca encontrar la palabra clave para luego posicionarse en el video\n",
        "import re\n",
        "\n",
        "def obtener_palabra_clave(frase):\n",
        "\n",
        "    patron_palabra_clave = r'(?:clase|video|contexto|link|enlace)\\s+(?:número\\s+\\d+\\s+)?(?:de\\s+)?(\\w+)'\n",
        "\n",
        "    # Buscar la palabra clave en la frase\n",
        "    coincidencia = re.search(patron_palabra_clave, frase, re.IGNORECASE)\n",
        "    if coincidencia:\n",
        "        return coincidencia.group(1)  # Devolver la palabra clave encontrada\n",
        "    else:\n",
        "        return None\n",
        "# Ejemplo de uso\n",
        "#frase = \"El enlace del video de YOLO es: https://youtu.be/YpgjXhaos9M\"\n",
        "#frase = \"El enlace del video embedding \"\n",
        "#frase = \"Necesito el link del video de YOLO\"\n",
        "#frase =\"quiero ver el video de YOLO\"\n",
        "#frase =\"cual es el link de vectores\"\n",
        "frase=      \"Necesito el link de embedding\"\n",
        "palabra_clave = obtener_palabra_clave(frase)\n",
        "if palabra_clave:\n",
        "    print(\"Palabra clave encontrada:\", palabra_clave)\n",
        "else:\n",
        "    print(\"No se encontró ninguna palabra clave.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XFDZ3InBngI",
        "outputId": "97b4b111-89d9-43d7-d879-ea0c88e66924"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabra clave encontrada: embedding\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prueba de funciones de app.py\n"
      ],
      "metadata": {
        "id": "bhfrDdTTgtEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install youtube-transcript-api\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "import re"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c82KUOXZg3F3",
        "outputId": "75416561-f51c-4dc1-92b8-a5eeba80a8d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: youtube-transcript-api in /usr/local/lib/python3.10/dist-packages (0.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube-transcript-api) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from html import escape\n",
        "ubicartiempo=YouTubeTranscriptApi"
      ],
      "metadata": {
        "id": "OqDHCQKfiKSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convertir_urls_a_enlaces(texto, pregunta1):\n",
        "    # Expresión regular para identificar URLs\n",
        "    patron_url = r'(https?://\\S+(?:&\\S+)*)'\n",
        "    urls = re.findall(patron_url, texto)\n",
        "    if urls: # Si hay URL, procesar\n",
        "        palabra_clave = obtener_palabra_clave(pregunta1)\n",
        "\n",
        "        enlaces_modificados = {}\n",
        "        for url in urls:\n",
        "\n",
        "\n",
        "            minuto_comienzo = buscar_minuto_comienzo(palabra_clave, url)\n",
        "\n",
        "            if minuto_comienzo is not None:\n",
        "\n",
        "                if 'youtube.com' in url or 'youtu.be' in url:\n",
        "                    segundos_inicio = int(minuto_comienzo * 60)\n",
        "                    if '?' in url:\n",
        "                        url_con_tiempo = f'{url}&t={segundos_inicio}s'\n",
        "\n",
        "                    else:\n",
        "                        url_con_tiempo = f'{url}?t={segundos_inicio}s'\n",
        "                    print(url_con_tiempo)\n",
        "                    input(\"LinK\")\n",
        "                   # enlaces_modificados[url] = f'<a href=\"{escape(url_con_tiempo)}\" target=\"_blank\">{escape(url_con_tiempo)}</a>'\n",
        "                    enlaces_modificados[url] = url_con_tiempo\n",
        "\n",
        "        # Reemplazar cada enlace en el texto con su versión modificada\n",
        "\n",
        "        for url, enlace_html in enlaces_modificados.items():\n",
        "            texto = texto.replace(url, enlace_html)\n",
        "\n",
        "    return texto\n",
        "def buscar_minuto_comienzo(clave, url1):\n",
        "    patron = r\"(?<=v=)([\\w-]+)\"\n",
        "    id = re.search(patron, url1)\n",
        "    if id:\n",
        "        _id = id.group(0)\n",
        "        transcripcion = ubicartiempo.get_transcript(_id, languages=('es',))\n",
        "        if transcripcion:\n",
        "            for item in transcripcion:\n",
        "               if 'text' in item and 'start' in item:\n",
        "                 if 'text' in item:\n",
        "\n",
        "                    if clave in item['text']:\n",
        "\n",
        "                        return item['start'] / 60  # Convertir segundos a minutos\n",
        "    return 0  # Devolver None si no se encuentra la clave\n",
        "def obtener_palabra_clave(frase):\n",
        "    patron_palabra_clave = r'(?:clase|video|contexto|link|enlace)\\s+(?:número\\s+\\d+\\s+)?(?:de\\s+)?(\\w+)'\n",
        "    # Buscar la palabra clave en la frase\n",
        "    coincidencia = re.search(patron_palabra_clave, frase, re.IGNORECASE)\n",
        "    if coincidencia:\n",
        "        return coincidencia.group(1)  # Devolver la palabra clave encontrada\n",
        "    else:\n",
        "        return \"\""
      ],
      "metadata": {
        "id": "8MeV6EaIfo7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "texto=\"Claro, aquí tienes los enlaces a los videos que tratan sobre YOLO: 1. Segmentación de objetos con YOLO (Parte 1): https://www.youtube.com/watch?v=IrySbxp1lnA 2. YOLO para detección de objetos (Parte 1): https://www.youtube.com/watch?v=TnLbGAKQGyE 3. YOLO para detección de objetos (Parte 2): https://www.youtube.com/watch?v=6pNLOlOH7vg 4. Clasificación de objetos con YOLOv8 (Parte 1): https://www.youtube.com/watch?v=ohHO3qSj9pM 5. Clasificación de objetos con YOLOv8 (Parte 2): https://www.youtube.com/watch?v=0KCVEQp9AzE\"\n",
        "pregunta1=\"tods los link de yolo\"\n",
        "respuesta = convertir_urls_a_enlaces(texto,pregunta1)\n",
        "print(respuesta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKUuLIBafuFl",
        "outputId": "db077ff7-78cf-4e23-ecc6-d12bb263ad3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://www.youtube.com/watch?v=IrySbxp1lnA&t=1632s\n",
            "LinK\n",
            "https://www.youtube.com/watch?v=TnLbGAKQGyE&t=956s\n",
            "LinK\n",
            "https://www.youtube.com/watch?v=6pNLOlOH7vg&t=0s\n",
            "LinK\n",
            "https://www.youtube.com/watch?v=ohHO3qSj9pM&t=0s\n",
            "LinK\n",
            "https://www.youtube.com/watch?v=0KCVEQp9AzE&t=0s\n",
            "LinK\n",
            "Claro, aquí tienes los enlaces a los videos que tratan sobre YOLO: 1. Segmentación de objetos con YOLO (Parte 1): https://www.youtube.com/watch?v=IrySbxp1lnA&t=1632s 2. YOLO para detección de objetos (Parte 1): https://www.youtube.com/watch?v=TnLbGAKQGyE&t=956s 3. YOLO para detección de objetos (Parte 2): https://www.youtube.com/watch?v=6pNLOlOH7vg&t=0s 4. Clasificación de objetos con YOLOv8 (Parte 1): https://www.youtube.com/watch?v=ohHO3qSj9pM&t=0s 5. Clasificación de objetos con YOLOv8 (Parte 2): https://www.youtube.com/watch?v=0KCVEQp9AzE&t=0s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CPrMEF_Oq0WS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (respuesta)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOPbJqvziO7s",
        "outputId": "996b4d3e-04cf-4ae3-f17b-faf92b9eed77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Claro, aquí tienes los enlaces que proporcionaste anteriormente: - Clase30 (parte 1) https://www.youtube.com/watch?v=eEO4d-c15lU - Sistema de respuesta con base de datos propia en PDF - Clase29 (parte 1) https://www.youtube.com/watch?v=geVYnK3p2CE - Componentes principales - Clase29 (parte 2) https://www.youtube.com/watch?v=Ehw9F3Mi9QI - Componentes principales - Clase30 (parte 2) https://www.youtube.com/watch?v=q2Jteb_auXU - Sistema de respuesta con base de datos propia en PDF Espero que estos enlaces te sean útiles.\n"
          ]
        }
      ]
    }
  ]
}